{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".container {\n",
    "  width: 100%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import nbimporter\n",
    "from AIBaseClass import ChessAI\n",
    "from Exercise03AI import Exercise03AI\n",
    "from Exercise04AI import Exercise04AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentelle KI\n",
    "\n",
    "Diese KI-Version implementiert mehrere Ideen für eine erhöhte Performance:\n",
    "\n",
    "1. Rotierender Cache der letzten zwei Halbzüge statt vollständiges Caching\n",
    "2. Kein Progressive Deepening aber weiterhin Zugsortierung mithilfe des Cache\n",
    "3. Entfernen der Tiefe aus dem Cache-Key für bessere Zugsortierung und mehr Cache-Hits\n",
    "\n",
    "Aus Zeitgründen ist diese KI nur rudimentär beschrieben und besitzt keine eigenen Unit-Tests. Die folgenden Statistiken zeigen eine deutliche Steigerung der Berechnungsgeschwindigkeit, bei weiterhin gleichbleibenden Ergebnissen. Demnach ist diese Version die bisher schnellste KI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die folgende Statistik zeigt, dass die `ExperimentalAI` ähnliche Ergebnisse gegen Stockfish erzielt wie die vorherige Version `Exercise08AI`.\n",
    "<img src=\"images/Stockfish_vs_ExperimentalAI.png\" width=\"1000px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das folgende Bild zeigt, dass die `ExperimentalAI` durchschnittlich am Schnellsten rechnet pro Zug rechnet.\n",
    "<img src=\"images/ExperimentalAI_duration.png\" width=\"1200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die folgende Statistik zeigt, dass die `ExperimentalAI` durchschnittlich die geringste Anzahl an Knoten untersucht.\n",
    "<img src=\"images/ExperimentalAI_nodes.png\" width=\"1200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das folgende Bild zeigt, dass die `ExperimentalAI` eine geringere Cache-Größe aufweist, als die vorherige Version `Exercise08AI`.\n",
    "<img src=\"images/ExperimentalAI_cache_size.png\" width=\"1200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die folgende Statistik zeigt, dass die `ExperimentalAI` in etwa gleich viele Cache Hits wie die vorherige Version `Exercise08AI` aufweist.\n",
    "<img src=\"images/ExperimentalAI_cache_hits.png\" width=\"1200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "from typing import Any, Callable\n",
    "\n",
    "\n",
    "class ExperimentalAI(Exercise03AI):\n",
    "    \"\"\"Chooses middle game moves using minimax algorithm, alpha-beta-pruning,\n",
    "    memoization, progressive deepening and the singular value extension.\"\"\"\n",
    "\n",
    "    def __init__(self, max_depth: int = 8, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.cache_new: dict[tuple, Any] = {}\n",
    "        self.cache_old: dict[tuple, Any] = {}\n",
    "        self.MAX_SVE_DEPTH: int = max(max_depth, kwargs[\"search_depth\"])\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets all internal variables.\"\"\"\n",
    "        super().reset()\n",
    "        self.cache_new.clear() # NEW: current move calculation cache\n",
    "        self.cache_old.clear() # NEW: last move calculation cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentalAI(ExperimentalAI):  # type: ignore\n",
    "    def is_quiet_move_and_push(self, board: chess.Board, move: chess.Move) -> bool:\n",
    "        \"\"\"Checks if the next move was an promotion, capture or check move. Pushes the given move on the board.\"\"\"\n",
    "        if move.promotion or board.piece_type_at(move.to_square):\n",
    "            board.push(move)\n",
    "            return False\n",
    "        board.push(move)\n",
    "        if board.is_check():\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentalAI(ExperimentalAI):  # type: ignore\n",
    "    def minimax_early_abort(\n",
    "        self, board: chess.Board, level: int, depth: int, current_evaluation: int\n",
    "    ) -> int | None:\n",
    "        \"\"\"Returns an evaluation iff the minimax has an early exit condition. Returns None otherwise.\"\"\"\n",
    "        is_checkmate = board.is_checkmate()\n",
    "        if is_checkmate and not board.turn:\n",
    "            # White has won the game\n",
    "            evaluation = self.LIMIT - level\n",
    "            return evaluation\n",
    "\n",
    "        if is_checkmate and board.turn:\n",
    "            # Black has won the game\n",
    "            evaluation = -self.LIMIT + level\n",
    "            return evaluation\n",
    "\n",
    "        if (\n",
    "            board.is_insufficient_material()\n",
    "            or not board.legal_moves\n",
    "            or board.is_fifty_moves()\n",
    "        ):\n",
    "            # Game is a draw\n",
    "            return 0\n",
    "\n",
    "        # Recursion abort case\n",
    "        if depth == 0:\n",
    "            return current_evaluation\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentalAI(ExperimentalAI):  # type: ignore\n",
    "    def maxValue(\n",
    "        self,\n",
    "        board: chess.Board,\n",
    "        current_evaluation: int,\n",
    "        depth: int,\n",
    "        level: int,\n",
    "        alpha: int,\n",
    "        beta: int,\n",
    "    ) -> tuple[int, chess.Move | None]:\n",
    "        \"\"\"Searches the best value with given depth using minimax algorithm.\"\"\"\n",
    "        self.stats[-1][\"nodes\"] += 1\n",
    "        early_abort_evaluation = self.minimax_early_abort(board, level, depth, current_evaluation)\n",
    "        if early_abort_evaluation is not None:\n",
    "            self.stats[-1][\"leaf_ctr\"] += 1\n",
    "            self.stats[-1][\"depth_sum\"] += level  # for calculating the average depth\n",
    "            return early_abort_evaluation, None\n",
    "\n",
    "        best_move = None\n",
    "        moves: list[tuple[int, int, chess.Move]] = []\n",
    "\n",
    "        # White to play (positive numbers are good)\n",
    "        if level < self.DEPTH - 2: # NEW: only sort moves if there should be something in the cache\n",
    "            for i, move in enumerate(board.legal_moves):\n",
    "                board.push(move)\n",
    "                key = self.get_key(board) # NEW: depth is not relevant here now\n",
    "                board.pop()\n",
    "                old_eval = self.cache_old.get(key, (None, i, None))[1]\n",
    "                heapq.heappush(moves, (-old_eval, i, move))\n",
    "        else:\n",
    "            moves = list(enumerate(board.legal_moves))\n",
    "        maxEvaluation = alpha\n",
    "        while moves:\n",
    "            move = heapq.heappop(moves)[-1]\n",
    "            new_evaluation = self.incremental_evaluate(board, current_evaluation, move)\n",
    "            if depth > 1 or level + 1 == self.MAX_SVE_DEPTH:\n",
    "                new_depth = depth\n",
    "                board.push(move)\n",
    "            elif self.is_quiet_move_and_push(board, move):\n",
    "                new_depth = depth\n",
    "            else:\n",
    "                new_depth = depth + 1\n",
    "            evaluation, _, = self.minimax(\n",
    "                self.minValue,\n",
    "                board,\n",
    "                new_evaluation,\n",
    "                new_depth - 1,\n",
    "                level + 1,\n",
    "                maxEvaluation,\n",
    "                beta,\n",
    "            )\n",
    "            board.pop()\n",
    "            if evaluation >= beta:\n",
    "                return evaluation, move\n",
    "            if evaluation > maxEvaluation:\n",
    "                best_move = move\n",
    "                maxEvaluation = evaluation\n",
    "        return maxEvaluation, best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentalAI(ExperimentalAI):  # type: ignore\n",
    "    def minValue(\n",
    "        self,\n",
    "        board: chess.Board,\n",
    "        current_evaluation: int,\n",
    "        depth: int,\n",
    "        level: int,\n",
    "        alpha: int,\n",
    "        beta: int,\n",
    "    ) -> tuple[int, chess.Move | None]:\n",
    "        \"\"\"Searches the best value with given depth using minimax algorithm.\"\"\"\n",
    "        self.stats[-1][\"nodes\"] += 1\n",
    "        early_abort_evaluation = self.minimax_early_abort(\n",
    "            board, level, depth, current_evaluation\n",
    "        )\n",
    "        if early_abort_evaluation is not None:\n",
    "            self.stats[-1][\"leaf_ctr\"] += 1\n",
    "            self.stats[-1][\"depth_sum\"] += level\n",
    "            return early_abort_evaluation, None\n",
    "\n",
    "        best_move = None\n",
    "        moves: list[tuple[int, int, chess.Move]] = []\n",
    "\n",
    "        # Black to play (negative numbers are good)\n",
    "        if level < self.DEPTH - 2: # NEW: only sort moves if there should be something in the cache\n",
    "            for i, move in enumerate(board.legal_moves):\n",
    "                board.push(move)\n",
    "                key = self.get_key(board) # NEW: depth is not relevant here now\n",
    "                board.pop()\n",
    "                old_eval = self.cache_old.get(key, (None, i, None))[1]\n",
    "                heapq.heappush(moves, (old_eval, i, move))\n",
    "        else:\n",
    "            moves = list(enumerate(board.legal_moves))\n",
    "        minEvaluation = beta\n",
    "        while moves:\n",
    "            move = heapq.heappop(moves)[-1]\n",
    "            new_evaluation = self.incremental_evaluate(board, current_evaluation, move)\n",
    "            if depth > 1 or level + 1 == self.MAX_SVE_DEPTH:\n",
    "                new_depth = depth\n",
    "                board.push(move)\n",
    "            elif self.is_quiet_move_and_push(board, move):\n",
    "                new_depth = depth\n",
    "            else:\n",
    "                new_depth = depth + 1\n",
    "            evaluation, _ = self.minimax(\n",
    "                self.maxValue,\n",
    "                board,\n",
    "                new_evaluation,\n",
    "                new_depth - 1,\n",
    "                level + 1,\n",
    "                alpha,\n",
    "                minEvaluation,\n",
    "            )\n",
    "            board.pop()\n",
    "            if evaluation <= alpha:\n",
    "                return evaluation, move\n",
    "            if evaluation < minEvaluation:\n",
    "                best_move = move\n",
    "                minEvaluation = evaluation\n",
    "        return minEvaluation, best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentalAI(ExperimentalAI):  # type: ignore\n",
    "    def get_key(self, board: chess.Board) -> tuple:\n",
    "        \"\"\"Calculates a key that uniquely identifies a given board.\"\"\"\n",
    "        return (\n",
    "            board.pawns,\n",
    "            board.knights,\n",
    "            board.bishops,\n",
    "            board.rooks,\n",
    "            board.queens,\n",
    "            board.kings,\n",
    "            board.occupied_co[chess.WHITE],\n",
    "            board.occupied_co[chess.BLACK],\n",
    "            board.turn,\n",
    "            board.castling_rights,\n",
    "            board.halfmove_clock\n",
    "            if board.halfmove_clock >= (50 - self.MAX_SVE_DEPTH)\n",
    "            else -42,\n",
    "        ) # NEW: no depth in the key anymore\n",
    "\n",
    "    def store_in_cache(\n",
    "        self, key: tuple, result: tuple, depth: int, alpha: int, beta: int\n",
    "    ) -> None:\n",
    "        \"\"\"Stores the result of a minimax computation in the cache.\"\"\"\n",
    "        evaluation, move = result\n",
    "        if evaluation <= alpha:\n",
    "            self.cache_new[key] = (\"≤\", evaluation, move, depth) # NEW: store depth as value inside the cache\n",
    "        elif evaluation < beta:\n",
    "            self.cache_new[key] = (\"=\", evaluation, move, depth)\n",
    "        else:\n",
    "            self.cache_new[key] = (\"≥\", evaluation, move, depth)\n",
    "\n",
    "    def get_from_cache(\n",
    "        self,\n",
    "        minValue_or_maxValue: Callable,\n",
    "        key: tuple,\n",
    "        board: chess.Board,\n",
    "        current_eval: int,\n",
    "        depth: int,\n",
    "        level: int,\n",
    "        alpha: int,\n",
    "        beta: int,\n",
    "    ) -> tuple:\n",
    "        \"\"\"Gets a result from the cache if possible.\"\"\"\n",
    "        flag, evaluation, move, eval_depth = self.cache_new.get(\n",
    "            key\n",
    "        ) or self.cache_old.get(key)\n",
    "        if depth > eval_depth: # NEW: if depth isn't sufficient do a normal search\n",
    "            result = minValue_or_maxValue(\n",
    "                board, current_eval, depth, level, alpha, beta\n",
    "            )\n",
    "            self.store_in_cache(key, result, depth, alpha, beta)\n",
    "            return result\n",
    "        if flag == \"=\":\n",
    "            return evaluation, move\n",
    "        elif flag == \"≤\":\n",
    "            if evaluation <= alpha:\n",
    "                return evaluation, move\n",
    "            elif evaluation < beta:\n",
    "                result = minValue_or_maxValue(\n",
    "                    board, current_eval, depth, level, alpha, evaluation\n",
    "                )\n",
    "                self.store_in_cache(key, result, depth, alpha, evaluation)\n",
    "                return result\n",
    "            else:\n",
    "                result = minValue_or_maxValue(\n",
    "                    board, current_eval, depth, level, alpha, beta\n",
    "                )\n",
    "                self.store_in_cache(key, result, depth, alpha, beta)\n",
    "                return result\n",
    "        else:\n",
    "            if evaluation <= alpha:\n",
    "                result = minValue_or_maxValue(\n",
    "                    board, current_eval, depth, level, alpha, beta\n",
    "                )\n",
    "                self.store_in_cache(key, result, depth, alpha, beta)\n",
    "                return result\n",
    "            elif evaluation < beta:\n",
    "                result = minValue_or_maxValue(\n",
    "                    board, current_eval, depth, level, evaluation, beta\n",
    "                )\n",
    "                self.store_in_cache(key, result, depth, evaluation, beta)\n",
    "                return result\n",
    "            else:\n",
    "                return evaluation, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ExperimentalAI(ExperimentalAI):  # type: ignore\n",
    "    def minimax(\n",
    "        self,\n",
    "        minValue_or_maxValue: Callable,\n",
    "        board: chess.Board,\n",
    "        current_evaluation: int,\n",
    "        depth: int,\n",
    "        level: int = 0,\n",
    "        alpha: int = -ExperimentalAI.LIMIT,\n",
    "        beta: int = ExperimentalAI.LIMIT,\n",
    "    ) -> tuple[int, chess.Move | None]:\n",
    "        \"\"\"Searches the best value with given depth using minimax algorithm.\"\"\"\n",
    "        key = self.get_key(board)\n",
    "        self.stats[-1][\"cache_tries\"] += 1\n",
    "        self.stats[-1][\"max_depth\"] = max(level, self.stats[-1][\"max_depth\"])\n",
    "\n",
    "        if key in self.cache_new or key in self.cache_old:\n",
    "            self.stats[-1][\"cache_hits\"] += 1\n",
    "            return self.get_from_cache(\n",
    "                minValue_or_maxValue,\n",
    "                key,\n",
    "                board,\n",
    "                current_evaluation,\n",
    "                depth,\n",
    "                level,\n",
    "                alpha,\n",
    "                beta,\n",
    "            )\n",
    "        result = minValue_or_maxValue(\n",
    "            board, current_evaluation, depth, level, alpha, beta\n",
    "        )\n",
    "        self.store_in_cache(key, result, depth, alpha, beta)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class ExperimentalAI(ExperimentalAI):  # type: ignore\n",
    "    def get_next_middle_game_move(self, board: chess.Board) -> chess.Move:\n",
    "        \"\"\"Gets the best next move.\"\"\"\n",
    "        self.last_evaluation: int | None  # type annotation for mypy\n",
    "        self.stats[-1][\"cache_hits\"] = 0\n",
    "        self.stats[-1][\"cache_tries\"] = 0\n",
    "        self.stats[-1][\"leaf_ctr\"] = 0\n",
    "        self.stats[-1][\"max_depth\"] = -1\n",
    "        self.stats[-1][\"avg_depth\"] = -1\n",
    "        self.stats[-1][\"depth_sum\"] = 0\n",
    "\n",
    "        if self.is_king_endgame != self.check_king_endgame(board):\n",
    "            self.last_evaluation += self.get_endgame_evaluation_change(board)\n",
    "        # Calculate current evaluation\n",
    "        if self.last_evaluation is None:  # type: ignore\n",
    "            current_evaluation = self.full_evaluate(board)\n",
    "        else:\n",
    "            # Get current evaluation (after opponent move)\n",
    "            last_move = board.pop()\n",
    "            current_evaluation = self.incremental_evaluate(board, self.last_evaluation, last_move)  # type: ignore\n",
    "            board.push(last_move)\n",
    "\n",
    "        evaluation_function = self.maxValue if board.turn else self.minValue\n",
    "        self.stats[-1][\"nodes\"] = 0\n",
    "        future_evaluation, best_move = self.minimax(\n",
    "            evaluation_function, board, current_evaluation, self.DEPTH\n",
    "        ) # NEW: no iterative deepening\n",
    "\n",
    "        # Debugging fail safe\n",
    "        assert best_move, f\"\"\"\n",
    "        Best move is None with fen '{board.fen()}' at player {type(self).__name__}! \n",
    "        depth: {self.DEPTH}, last_eval: {self.last_evaluation}, current_evaluation: {current_evaluation},\n",
    "        is_king_engame: {getattr(self, 'is_king_endgame', \"N/A\")}, move_stack: {board.move_stack}\n",
    "        \"\"\"\n",
    "        # Update last evaluation (after player move)\n",
    "        self.last_evaluation = self.incremental_evaluate(\n",
    "            board, current_evaluation, best_move\n",
    "        )\n",
    "        # Update stats\n",
    "        self.stats[-1][\"minimax_eval\"] = future_evaluation\n",
    "        self.stats[-1][\"board_eval_before_move\"] = current_evaluation\n",
    "        self.stats[-1][\"board_eval_after_move\"] = self.last_evaluation\n",
    "        self.stats[-1][\"avg_depth\"] = self.stats[-1][\"depth_sum\"] / (\n",
    "            self.stats[-1][\"leaf_ctr\"] or 1\n",
    "        )\n",
    "        del self.stats[-1][\"depth_sum\"]\n",
    "        del self.stats[-1][\"leaf_ctr\"]\n",
    "        self.stats[-1][\"cache_size_mb\"] = round(\n",
    "            (sys.getsizeof(self.cache_new) + sys.getsizeof(self.cache_old))\n",
    "            / (1024 * 1024),\n",
    "            2,\n",
    "        )\n",
    "        self.cache_old.clear() # NEW: rotate cache\n",
    "        self.cache_old = self.cache_new\n",
    "        self.cache_new = {}\n",
    "\n",
    "        self.stats[-1][\"datetime\"] = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Bereich\n",
    "\n",
    "Die folgenden Zellen enthalten Unit-Tests der oben implementierten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Exercise02AI as Exercise02AI_\n",
    "import Exercise04AI as Exercise04AI_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create player and board\n",
    "unit_test_player = ExperimentalAI(player_name=\"ExpAI\", search_depth=3, max_depth=3)\n",
    "board = chess.Board(\"5rk1/1b3p2/8/3p4/3p2P1/2Q4B/5P1K/R3R3 b - - 0 36\")\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test minimax\n",
    "def test_minimax(\n",
    "    unit_test_player: ChessAI,\n",
    "    board: chess.Board,\n",
    "    current_evaluation: int,\n",
    "    expected_evaluation: int,\n",
    "    expected_move: str,\n",
    "    expected_nodes: int,\n",
    "    expected_cache_tries: int,\n",
    "    expected_cache_hits: int,\n",
    "    expected_cache_elements: int,\n",
    "):\n",
    "    unit_test_player.cache_new = {}  # Clear cache\n",
    "    unit_test_player.cache_old = {}  # Clear cache\n",
    "    unit_test_player.stats[-1][\"cache_tries\"] = 0\n",
    "    unit_test_player.stats[-1][\"cache_hits\"] = 0\n",
    "    unit_test_player.stats[-1][\"nodes\"] = 0\n",
    "    unit_test_player.stats[-1][\"leaf_ctr\"] = 0\n",
    "    unit_test_player.stats[-1][\"max_depth\"] = 0\n",
    "    unit_test_player.stats[-1][\"depth_sum\"] = 0\n",
    "    f = unit_test_player.maxValue if board.turn else unit_test_player.minValue\n",
    "    mm_evaluation, mm_move = unit_test_player.minimax(\n",
    "        f, board, current_evaluation, unit_test_player.DEPTH\n",
    "    )\n",
    "    nodes = unit_test_player.stats[-1][\"nodes\"]\n",
    "    cache_tries = unit_test_player.stats[-1]['cache_tries']\n",
    "    cache_hits = unit_test_player.stats[-1]['cache_hits']\n",
    "    print(f\"Minimax Evaluation: {mm_evaluation}\")\n",
    "    print(f\"Minimax Move: {mm_move}\")\n",
    "    print(f\"Nodes searched: {nodes}\")\n",
    "    print(f\"Cache tries: {cache_tries}\")\n",
    "    print(f\"Cache hits: {cache_hits}\")\n",
    "    print(f\"Elements in new cache: {len(unit_test_player.cache_new)}\")\n",
    "    print(f\"Elements in old cache: {len(unit_test_player.cache_old)}\")\n",
    "    assert (\n",
    "        mm_evaluation == expected_evaluation\n",
    "    ), \"Minimax evaluation does not match expected value!\"\n",
    "    assert mm_move.uci() == expected_move, \"Minimax move does not match expected value!\"\n",
    "    assert nodes == expected_nodes, \"Searched node count has changed!\"\n",
    "    assert cache_tries == expected_cache_tries, \"Cache tries do not match expected value!\"\n",
    "    assert cache_hits == expected_cache_hits, \"Cache hits do not match expected value!\"\n",
    "    assert len(unit_test_player.cache_new) == expected_cache_elements, \"Cache elements do not match expected value!\"\n",
    "    assert len(unit_test_player.cache_old) == 0, \"Cache elements do not match expected value!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_minimax(\n",
    "    unit_test_player,\n",
    "    board,\n",
    "    current_evaluation=1240,\n",
    "    expected_evaluation=325,\n",
    "    expected_move=\"d4c3\",\n",
    "    expected_nodes=2336,\n",
    "    expected_cache_tries=2788,\n",
    "    expected_cache_hits=557,\n",
    "    expected_cache_elements=2231,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test next move function (with memoized minimax result)\n",
    "Exercise02AI_.test_next_move(\n",
    "    unit_test_player,\n",
    "    board,\n",
    "    expected_move=\"d4c3\",\n",
    "    expected_nodes=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
