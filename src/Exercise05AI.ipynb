{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".container {\n",
    "  width: 100%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from Exercise03AI import Exercise03AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 05: Minimax mit Alpha-Beta-Pruning\n",
    "\n",
    "Dieses Notebook implementiert den Minimax-Algorithmus mit Alpha-Beta-Pruning (ohne Memoisierung). Hierzu wird die `minimax`-Funktion adaptiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "\n",
    "class Exercise05AI(Exercise03AI):\n",
    "    \"\"\"Chooses middle game moves using minimax algorithm and alpha-beta-pruning\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax (aktualisiert)\n",
    "\n",
    "Die rekursive `minimax`-Funktion betrachtet bei einem gegebenen Board alle möglichen Stellungen (Boards) nach einer gegebenen Anzahl von Halbzügen (Tiefe) und gibt die beste Evaluierung (`evaluate`-Funktion) für den aktuellen Spieler zurück. Hierfür bekommt die Funktion als Argumente das aktuelle Board (`board`), die Evaluierungstiefe in Halbzügen (`depth`), die Evaluierung des übergebenen Boards (`current_evaluation`), eine untere Grenze für die Evaluierung (`alpha`) und eine obere Grenze für die Evaluierung (`beta`). Zurückgegeben wird ein Tupel bestehend aus der besten Evaluierung und des Halbzuges, der auf den Pfad zu dieser Evaluierung führt.\n",
    "\n",
    "Die folgende Implementierung des Minimax-Algorithmus ist zu großen Teilen mit der von `Exercise02AI` identisch. Als Neuerung wurde Alpha-Beta-Pruning hinzugefügt. Im Folgenden werden nur die Änderungen betrachtet:\n",
    "\n",
    "1. Die `minimax`-Funktion bekommt zwei zusätzliche Parameter $\\texttt{alpha}$ und $\\texttt{beta}$ welche mithilfe von Standardwerten beim ersten Aufruf auf das positive bzw. negative Limit gesetzt werden.\n",
    "2. Wenn der weiße Spieler am Zug ist (Maximierung) wird `maxEvaluation` auf den Wert $\\texttt{alpha}$ gesetzt. Wie bisher wird nun jeder Zug evaluiert. Hierbei wird das Maximum der bisherigen Evaluationen jeweils als neue untere Grenze $\\texttt{alpha}$ eingesetzt. Falls eine Evaluierung größer oder gleich $\\texttt{beta}$ ist, wird die Suche abgebrochen (pruning) und diese Evaluierung zurückgegeben.\n",
    "2. Falls der schwarze Spieler am Zug ist (Minimierung) wird `minEvaluation` auf den Wert $\\texttt{beta}$ gesetzt. Wie bisher wird nun jeder Zug evaluiert. Hierbei wird das Minimum der bisherigen Evaluationen jeweils als neue obere Grenze $\\texttt{beta}$ eingesetzt. Falls eine Evaluierung kleiner oder gleich $\\texttt{alpha}$ ist, wird die Suche abgebrochen (pruning) und diese Evaluierung zurückgegeben.\n",
    "\n",
    "Für einen Aufruf mit Weiß am Zug gilt also: \n",
    "$$\\texttt{return_value} = \\begin{cases}\n",
    "\\texttt{alpha} \\quad \\textrm{falls} \\quad \\texttt{evaluation} < \\texttt{alpha} \\quad \\textrm{für alle} \\quad \\texttt{move} \\in \\texttt{board.legal_moves},\\\\\n",
    "\\ge \\texttt{beta} \\quad \\textrm{falls} \\quad \\texttt{move} \\in \\texttt{board.legal_moves} \\quad \\textrm{mit} \\quad \\texttt{evaluation} \\ge \\texttt{beta} \\quad \\textrm{existiert,}\\\\\n",
    "\\texttt{evaluation} \\quad \\textrm{sonst}.\n",
    "\\end{cases}$$\n",
    "Für einen Aufruf mit Schwarz am Zug gilt: \n",
    "$$\\texttt{return_value} = \\begin{cases}\n",
    "\\texttt{beta} \\quad \\textrm{falls} \\quad \\texttt{evaluation} > \\texttt{beta} \\quad \\textrm{für alle} \\quad \\texttt{move} \\in \\texttt{board.legal_moves},\\\\\n",
    "\\le \\texttt{alpha} \\quad \\textrm{falls} \\quad move \\in \\texttt{board.legal_moves} \\quad \\textrm{mit} \\quad \\texttt{evaluation} \\le \\texttt{alpha} \\quad \\textrm{existiert,}\\\\\n",
    "\\texttt{evaluation} \\quad \\textrm{sonst}.\n",
    "\\end{cases}$$\n",
    "Somit ist in beiden Fällen die Spezifikation für das Alpha-Beta-Pruning erfüllt und das Programm liefert dieselbe Auswertung wie die Implementierung in `Exercise02AI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class Exercise05AI(Exercise05AI):  # type: ignore\n",
    "    def minimax(\n",
    "        self,\n",
    "        board: chess.Board,\n",
    "        depth: int,\n",
    "        current_evaluation: int,\n",
    "        alpha: int = -Exercise05AI.LIMIT,\n",
    "        beta: int = Exercise05AI.LIMIT,\n",
    "    ) -> tuple[int, chess.Move | None]:\n",
    "        \"\"\"Searches the best value with a given depth using the minimax algorithm\"\"\"\n",
    "        self.stats[-1][\"nodes\"] += 1\n",
    "        early_abort_evaluation = self.minimax_early_abort(\n",
    "            board, depth, current_evaluation\n",
    "        )\n",
    "        if early_abort_evaluation is not None:\n",
    "            return early_abort_evaluation, None\n",
    "\n",
    "        best_move = None\n",
    "\n",
    "        # White to play (positive numbers are good)\n",
    "        if board.turn:\n",
    "            maxEvaluation = alpha\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(\n",
    "                    board,\n",
    "                    depth - 1,\n",
    "                    self.evaluate(board, current_evaluation),\n",
    "                    maxEvaluation,\n",
    "                    beta,\n",
    "                )\n",
    "                board.pop()\n",
    "                if evaluation >= beta:\n",
    "                    return evaluation, move\n",
    "                if depth == self.DEPTH and evaluation > maxEvaluation:\n",
    "                    best_move = move\n",
    "                maxEvaluation = max(maxEvaluation, evaluation)\n",
    "            return maxEvaluation, best_move\n",
    "\n",
    "        # Black to play (negative numbers are good)\n",
    "        else:\n",
    "            minEvaluation = beta\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(\n",
    "                    board,\n",
    "                    depth - 1,\n",
    "                    self.evaluate(board, current_evaluation),\n",
    "                    alpha,\n",
    "                    minEvaluation,\n",
    "                )\n",
    "                board.pop()\n",
    "                if evaluation <= alpha:\n",
    "                    return evaluation, move\n",
    "                if depth == self.DEPTH and evaluation < minEvaluation:\n",
    "                    best_move = move\n",
    "                minEvaluation = min(minEvaluation, evaluation)\n",
    "            return minEvaluation, best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Bereich\n",
    "\n",
    "Die folgenden Zellen enthalten Unit-Tests der oben implementierten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AIBaseClass import ChessAI\n",
    "import Exercise02AI as Exercise02AI_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create player and board\n",
    "unit_test_player = Exercise05AI(player_name=\"Ex05AI\", search_depth=3)\n",
    "board = chess.Board(\"5rk1/1b3p2/8/3p4/3p2P1/2Q4B/5P1K/R3R3 b - - 0 36\")\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use minimax test without memoization\n",
    "Exercise02AI_.test_minimax(\n",
    "    unit_test_player,\n",
    "    board,\n",
    "    current_evaluation=1240,\n",
    "    expected_evaluation=325,\n",
    "    expected_move=\"d4c3\",\n",
    "    expected_nodes=2788,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporärer Bereich\n",
    "\n",
    "Der folgende Bereich dient zum temporären Debuggen und kann nicht-funktionierenden Code enthalten. Dieser Bereich wird vor der Abgabe entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
