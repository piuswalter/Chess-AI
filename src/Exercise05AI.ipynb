{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".container {\n",
    "  width: 100%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from AIBaseClass import ChessAI\n",
    "from Exercise03AI import Exercise03AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 05: Minimax mit Alpha-Beta-Pruning\n",
    "\n",
    "Dieses Notebook implementiert den Minimax-Algorithmus mit Alpha-Beta-Pruning (ohne Memoisierung). Hierzu wird die `minimax`-Funktion verändert (überschrieben)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess_custom as chess\n",
    "\n",
    "class Exercise05AI(Exercise03AI):\n",
    "    \"\"\"Chooses middle game moves using minimax algorithm and alpha-beta-pruning\"\"\"\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax (aktualisiert)\n",
    "\n",
    "Die folgende Implementierung des Minimax-Algorithmus ist zu großen Teilen mit der von `Exercise02AI` identisch. Als Neuerung wurde Alpha-Beta-Pruning hinzugefügt. Im Folgenden werden nur die Änderungen betrachtet:\n",
    "\n",
    "1. Die `minimax`-Funktion bekommt zwei zusätzliche Parameter $alpha$ und $beta$ welche mithilfe von Standardwerten beim ersten Aufruf auf das positive bzw. negative Limit gesetzt werden.\n",
    "2. Wenn der weiße Spieler am Zug ist (Maximierung) wird `maxEvaluation` auf den Wert $alpha$ gesetzt. Wie bisher wird nun jeder Zug evaluiert. Hierbei wird das Maximum der bisherigen Evaluationen jeweils als neue untere Grenze $alpha$ eingesetzt. Falls eine Evaluierung größer oder gleich $beta$ ist, wird die Suche abgebrochen (pruning) und diese Evaluierung zurückgegeben.\n",
    "2. Falls der schwarze Spieler am Zug ist (Minimierung) wird `minEvaluation` auf den Wert $beta$ gesetzt. Wie bisher wird nun jeder Zug evaluiert. Hierbei wird das Minimum der bisherigen Evaluationen jeweils als neue obere Grenze $beta$ eingesetzt. Falls eine Evaluierung kleiner oder gleich $alpha$ ist, wird die Suche abgebrochen (pruning) und diese Evaluierung zurückgegeben.\n",
    "\n",
    "Für einen Aufruf mit Weiß am Zug gilt also: \n",
    "$$return\\_value = \\begin{cases}\n",
    "alpha \\quad \\texttt{falls} \\quad evaluation < alpha \\quad \\texttt{für alle} \\quad move \\in board.legal\\_moves,\\\\\n",
    "\\ge beta \\quad \\texttt{falls} \\quad move \\in board.legal\\_moves \\quad \\texttt{mit} \\quad evaluation \\ge beta \\quad \\texttt{existiert,}\\\\\n",
    "evaluation \\quad \\texttt{sonst}.\n",
    "\\end{cases}$$\n",
    "Für einen Aufruf mit Schwarz am Zug gilt: \n",
    "$$return\\_value = \\begin{cases}\n",
    "beta \\quad \\texttt{falls} \\quad evaluation > beta \\quad \\texttt{für alle} \\quad move \\in board.legal\\_moves,\\\\\n",
    "\\le alpha \\quad \\texttt{falls} \\quad move \\in board.legal\\_moves \\quad \\texttt{mit} \\quad evaluation \\le alpha \\quad \\texttt{existiert,}\\\\\n",
    "evaluation \\quad \\texttt{sonst}.\n",
    "\\end{cases}$$\n",
    "Somit ist in beiden Fällen die Spezifikation für das Alpha-Beta-Pruning erfüllt und das Programm liefert dieselbe Auswertung wie die Implementierung in `Exercise02AI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class Exercise05AI(Exercise05AI): # type: ignore\n",
    "    \n",
    "    def minimax(self, board: chess.Board, depth: int, current_evaluation: int,\n",
    "                alpha: int = -Exercise05AI.LIMIT, beta: int = Exercise05AI.LIMIT) -> tuple[int, chess.Move]:\n",
    "        \"\"\"Searches the best value with a given depth using the minimax algorithm\"\"\"\n",
    "        best_move = None\n",
    "        \n",
    "        if (is_checkmate := board.is_checkmate()) and not board.turn:\n",
    "            # White has won the game\n",
    "            evaluation = self.LIMIT - (self.DEPTH - depth)\n",
    "            return evaluation, None\n",
    "        elif is_checkmate and board.turn:\n",
    "            # Black has won the game\n",
    "            evaluation = -self.LIMIT + (self.DEPTH - depth)\n",
    "            return evaluation, None\n",
    "        elif board.is_insufficient_material() or not board.legal_moves or board.is_fifty_moves() or board.is_repetition(5):\n",
    "            # Game is a draw\n",
    "            return 0, None\n",
    "\n",
    "        # Recursion abort case\n",
    "        if depth == 0:\n",
    "            return current_evaluation, None\n",
    "\n",
    "        # White to play (positive numbers are good)\n",
    "        if board.turn:\n",
    "            maxEvaluation = alpha\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(board, depth - 1, self.evaluate(board, current_evaluation), maxEvaluation, beta)\n",
    "                board.pop()\n",
    "                if evaluation >= beta:\n",
    "                    return evaluation, move\n",
    "                if depth == self.DEPTH and evaluation > maxEvaluation:\n",
    "                    best_move = move\n",
    "                maxEvaluation = max(maxEvaluation, evaluation)\n",
    "            return maxEvaluation, best_move\n",
    "\n",
    "        # Black to play (negative numbers are good)\n",
    "        else:\n",
    "            minEvaluation = beta\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(board, depth - 1, self.evaluate(board, current_evaluation), alpha, minEvaluation)\n",
    "                board.pop()\n",
    "                if evaluation <= alpha:\n",
    "                    return evaluation, move\n",
    "                if depth == self.DEPTH and evaluation < minEvaluation:\n",
    "                    best_move = move\n",
    "                minEvaluation = min(minEvaluation, evaluation)\n",
    "            return minEvaluation, best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Bereich\n",
    "\n",
    "Die folgenden Zellen enthalten Code zum Testen der oben implementierten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xmode Plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "from Exercise03AI import Exercise03AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "board = chess.Board(\"5rk1/1b3p2/8/3p4/3p2P1/2Q4B/5P1K/R3R3 w - - 0 36\")\n",
    "board.push(chess.Move.from_uci(\"h2h1\"))\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "DEPTH = 3\n",
    "player3 = Exercise03AI(\"Testplayer\", DEPTH)\n",
    "#print(player.minimax(board, DEPTH))\n",
    "move = player3.get_next_middle_game_move(board)\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "DEPTH = 3\n",
    "player5 = Exercise05AI(\"Testplayer\", DEPTH)\n",
    "#print(player.minimax(board, DEPTH))\n",
    "move = player5.get_next_middle_game_move(board)\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "from IPython.display import clear_output, display\n",
    "player5 = Exercise05AI(\"Testplayer\", 3)\n",
    "player3 = Exercise03AI(\"Testplayer\", 3)\n",
    "move = player3.random.choice(list(board.legal_moves))\n",
    "board.push(move)\n",
    "for _ in range(10):\n",
    "    move_1, eval_1 = player3.get_next_middle_game_move(board)\n",
    "    player3.last_evaluation = None\n",
    "    print(move_1, eval_1, player3.last_evaluation)\n",
    "    move_2, eval_2 = player5.get_next_middle_game_move(board)\n",
    "    player5.last_evaluation = None\n",
    "    print(move_2, eval_2, player5.last_evaluation)\n",
    "    move = player3.random.choice(list(board.legal_moves))\n",
    "    board.push(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "DEPTH = 3\n",
    "board = chess.Board()\n",
    "#board.set_fen(\"4k3/8/2n5/7K/5q2/2N5/8/2B5 b - - 0 1\")\n",
    "player = Exercise04AI(\"Testplayer\", DEPTH)\n",
    "for _ in range(10):\n",
    "    board.push(sorted(board.legal_moves, key=lambda move: move.uci())[0])\n",
    "    move = player.get_next_middle_game_move(board)\n",
    "    print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "from os.path import join\n",
    "\n",
    "with open(join(\"..\", \"games\", \"2022-01-15_20-18-57-907777.pgn\")) as pgn:\n",
    "    first_game = chess.pgn.read_game(pgn)\n",
    "\n",
    "# Iterate through all moves and play them on a board.\n",
    "board = first_game.board()\n",
    "for move in first_game.mainline_moves():\n",
    "    board.push(move)\n",
    "for i in range(220):\n",
    "    board.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "DEPTH = 2\n",
    "#board = chess.Board()\n",
    "#board.set_fen(\"4k3/8/2n5/7K/5q2/2N5/8/2B5 b - - 0 1\")\n",
    "player = Exercise04AI(\"Testplayer\", DEPTH)\n",
    "#print(player.minimax(board, DEPTH))\n",
    "move = player.get_next_middle_game_move(board)\n",
    "print(move)\n",
    "player.cache_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "board = chess.Board(\"7B/pbpk4/1p6/2n1pp2/6p1/4P3/P1P2PNP/RNq1K1R1 w - - 0 1\")\n",
    "player = Exercise04AI(\"Testplayer\", 3)\n",
    "print(player.evaluate(board))\n",
    "board"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
