{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".container {\n",
    "  width: 100%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from AIBaseClass import ChessAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 02: Minimax (einfacher Materialwert)\n",
    "\n",
    "Diese Klasse implementiert den Minimax-Algorithmus zur Berechnung des nächsten Zuges im Mittelspiel. Die Evaluierung eines Boards wird dabei durch Betrachtung des Materialwertes der Figuren realisiert.\n",
    "\n",
    "Die Klasse wird um eine neue Konstante `DEPTH` erweitert. Diese gibt an, wie viele zukünftige Halbzüge bei der Berechnung des nächsten Zuges betrachtet werden sollen, das heißt, welche Höhe der entsprechende Baum aller möglichen nächsten Halbzüge aufweist. Die Konstante wird als Parameter übergeben und im Konstruktor gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import os\n",
    "\n",
    "class Exercise02AI(ChessAI):\n",
    "    \"\"\"Chooses middle game moves using minimax algorithm and material values\"\"\"\n",
    "\n",
    "    def __init__(self, player_name: str, search_depth: int = 3) -> None:\n",
    "        super().__init__(player_name)\n",
    "        self.DEPTH = int(os.environ.get(\"depth\", search_depth))\n",
    "        self.evaluations: dict[str, int] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierungsfunktion\n",
    "\n",
    "Die Evaluierungsfunktion `evaluate` nimmt ein Board als Argument und berechnet eine Ganzzahl als Maß dafür, ob die gegebene Stellung für den weißen Spieler eher zu einem Sieg (positiver Wert) oder zu einer Niederlage (negativer Wert) führt.\n",
    "\n",
    "Diese Implementierung verwendet dafür den Materialwert (Tauschwert in Bauerneinheiten) nach folgender Tabelle:\n",
    "\n",
    "| Figurname  | Materialwert |\n",
    "|---|---|\n",
    "| Bauer (pawn) | 1  |\n",
    "| Springer (knight) | 3  |\n",
    "| Läufer (bishop) | 3  |\n",
    "| Turm (rook) | 5  |\n",
    "| Dame (queen) | 9  |\n",
    "| König (king) | 20000 |\n",
    "\n",
    "Für die Berechnung des nächsten Schrittes stehen mehrere Funktionen zur Verfügung:\n",
    "\n",
    "- `full_evaluate`\n",
    "- `get_cache_evaluation`\n",
    "- `incremental_evaluate`\n",
    "- `evaluate`\n",
    "\n",
    "Die Funktion `full_evaluate` berechnet den Wert eines Boards von Grund auf neu und geht dabei wie folgt vor:\n",
    "\n",
    "1. Es wird für jede Figur und für jede Farbe die Anzahl der Spielfiguren ermittelt.\n",
    "2. Für jede Figur wird die Differenz der Anzahl pro Farbe gebildet ($\\texttt{Weiß} - \\texttt{Schwarz}$)\n",
    "3. Jede Differenz wird mit dem figurenspezifischen Faktor multipliziert und zur Gesamtsumme addiert.\n",
    "\n",
    "`get_cache_evaluation` greift auf den angelegten Cache zu, gibt den dort gespeicherten Wert zurück oder ruft die Funktion `full_evaluate` auf falls kein Eintrag vorhanden ist. \n",
    "Die Funktion `incremental_evaluate` greift über die zuvor beschriebene Cache-Funktion auf das bereits berechnete Board zurück, prüft die Änderung zum aktuellen Board und berechnet anhand dessen die Differenz. Hierfür werden die drei Fälle untersucht in denen sich der Wert verändert haben kann:\n",
    "\n",
    "1. Ein En Passant Zug wurde durchgeführt\n",
    "2. Eine Figur wurde geschlagen\n",
    "3. Ein Bauer wurde in eine neue Figur umgewandelt\n",
    "\n",
    "Die Funktion `evaluate` speichert den Rückgabewert der inkrementellen Berechnung im Cache und gibt ihn anschließend zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI): # type: ignore\n",
    "    MATERIAL_VALUES = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 9,\n",
    "        chess.KING: 20000\n",
    "    }\n",
    "\n",
    "    def full_evaluate(self, board: chess.Board) -> int:\n",
    "        \"\"\"Returns a full evaluation of the given board.\"\"\"\n",
    "        evaluation = 0\n",
    "        for piece_type in chess.PIECE_TYPES:\n",
    "            # Get the amount of pieces on the board per color\n",
    "            amount_type_white   = len(board.pieces(piece_type,   chess.WHITE))\n",
    "            amount_type_black   = len(board.pieces(piece_type,   chess.BLACK))\n",
    "            # Get difference\n",
    "            diff = amount_type_white - amount_type_black\n",
    "            # Calculate material value\n",
    "            evaluation += self.MATERIAL_VALUES[piece_type] * diff\n",
    "        return evaluation\n",
    "\n",
    "    def get_cache_evaluation(self, board: chess.Board) -> int:\n",
    "        \"\"\"Returns the evaluation for the given board from the cache.\"\"\"\n",
    "        # Calculate dictionary key\n",
    "        short_fen = board.fen().split(\" \")[0]\n",
    "        # Get evaluation from cache\n",
    "        evaluation = self.evaluations.get(short_fen)\n",
    "        # Calculate if there is no evaluation yet\n",
    "        if evaluation is None:\n",
    "            evaluation = self.full_evaluate(board)\n",
    "            self.evaluations[short_fen] = evaluation\n",
    "        return evaluation\n",
    "\n",
    "    def incremental_evaluate(self, board: chess.Board) -> int:\n",
    "        \"\"\"Returns an incrementally calculated evaluation of the given board.\"\"\"\n",
    "        # Get and remove last move\n",
    "        move = board.pop()\n",
    "        # Start with old evaluation as base value\n",
    "        evaluation = self.get_cache_evaluation(board)\n",
    "        change = 0\n",
    "        \n",
    "        if board.is_en_passant(move):\n",
    "            change = self.MATERIAL_VALUES[chess.PAWN]\n",
    "\n",
    "        if captured_piece_type := board.piece_type_at(move.to_square):\n",
    "            change = self.MATERIAL_VALUES[captured_piece_type]\n",
    "\n",
    "        if promotion_piece_type := move.promotion:\n",
    "            change = self.MATERIAL_VALUES[promotion_piece_type] - self.MATERIAL_VALUES[chess.PAWN]\n",
    "        \n",
    "        # Add to old evaluation if white to move, else subtract\n",
    "        factor = +1 if board.turn else -1\n",
    "        evaluation += change * factor\n",
    "        # Restore board\n",
    "        board.push(move)\n",
    "        return evaluation\n",
    "\n",
    "    def evaluate(self, board: chess.Board) -> int:\n",
    "        \"\"\"Evaluates a given board. \n",
    "        Returns a positive value if white has a better material value than black.\"\"\"\n",
    "        # Calculate new dictionary key\n",
    "        short_fen = board.fen().split(\" \")[0]\n",
    "\n",
    "        # Calculate evaluation incrementally\n",
    "        evaluation = self.incremental_evaluate(board)\n",
    "\n",
    "        # Save evaluation\n",
    "        self.evaluations[short_fen] = evaluation\n",
    "        return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fünffache Stellungswiederholung\n",
    "\n",
    "Im Schach besagt die `fivefold repetition`-Regel, dass ein Spiel sofort als Remis gewertet wird, falls sich eine Stellung zum fünften Mal wiederholt. Zwei Stellungen gelten dabei als gleich g. d. w. die Boardbelegung (Farbe, Figurtyp, Position) und die möglichen Züge dieselben sind.\n",
    "Die Prüfung auf eine Stellungswiederholung ist in der `chess`-Bibliothek sehr langsam, da im schlechtesten Fall das gesamte Spiel neu durchlaufen werden muss (siehe Dokumentation). Die Funktion `maybe_repetitions` führt daher nur eine einfache Prüfung mithilfe der Boardbelegung durch und gibt die Anzahl der möglichen Wiederholungen der aktuellen Position zurück. Das Restrisiko, dass eine erkannte Wiederholung keine solche ist (z.B. andere Rochade-Rechte oder En-Passant-Züge möglich) wird akzeptiert, da es als sehr gering eingestuft wird. Diese einfache Prüfung wird innerhalb des Minimax-Algorithmus verwendet, nach jedem abgeschlossenen Zug findet ein vollständiger Test statt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI): # type: ignore\n",
    "\n",
    "    def maybe_repetitions(self, board: chess.Board) -> int:\n",
    "        \"\"\"Does a fast check if the current position has repeated multiple\n",
    "        times and returns the number of repetitions.\n",
    "        Does NOT check for castling rights and en passant captures.\"\"\"\n",
    "        # Fast check, based on occupancy only.\n",
    "        maybe_repetitions = 1\n",
    "        for state in reversed(board._stack):\n",
    "            if state.occupied == board.occupied:\n",
    "                maybe_repetitions += 1\n",
    "        return maybe_repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax\n",
    "\n",
    "Die rekursive `minimax`-Funktion betrachtet bei einem gegebenen Board alle möglichen Stellungen (Boards) nach einer gegebenen Anzahl von Halbzügen (Tiefe) und gibt die beste Evaluierung (`evaluate`-Funktion) für den aktuellen Spieler zurück.\n",
    "\n",
    "Die Konstante `LIMIT` wird als obere (+) beziehungsweise untere (-) Schranke für den Vergleich innerhalb der ersten Iteration verwendet.\n",
    "\n",
    "Folgende Fälle werden unterschieden:\n",
    "\n",
    "1. Falls das Spiel beendet ist, werden die drei folgenden Möglichkeiten unterschieden:\n",
    "    - Das Spiel ist ein Remis:\n",
    "    In diesem Fall wird 0 als Wert zurückgegeben. Der Zug welcher zu diesem Zustand führt wird also nur gewählt, sofern jeder andere Zug zu einem für die Seite schlechteren Wert (und somit eher zu einer Niederlage) führt.\n",
    "    - Weiß hat das Spiel gewonnen:\n",
    "    Hier wird das positive Limit (`99999`) zurückgegeben, welches auf jeden Fall größer oder gleich dem Evaluierungswert aller anderen Züge ist. Weiß wird daher diesen (oder einen in dieser Hinsicht gleichwertigen) Zug wählen um das Spiel zu gewinnen, Schwarz versucht den Zug möglichst zu vermeiden.\n",
    "    - Schwarz hat das Spiel gewonnen:\n",
    "    Das negative Limit (`-99999`) wird zurückgegeben. Dieses ist auf jeden Fall kleiner oder gleich dem Evaluierungswert aller anderen Züge. Schwarz wird daher diesen (oder einen in dieser Hinsicht gleichwertigen) Zug wählen um das Spiel zu gewinnen, Weiß versucht den Zug möglichst zu vermeiden.\n",
    "2. Falls die Tiefe Null ist, wird die Auswertung des aktuellen Boards zurückgegeben (Rekursionsende).\n",
    "3. Falls Weiß am Zug ist, wird jeder mögliche Zug rekursiv evaluiert und das Maximum der Ergebnisse zurückgegeben.\n",
    "4. Falls Schwarz am Zug ist, wird jeder mögliche Zug rekursiv evaluiert und das Minimum der Ergebnisse zurückgegeben.\n",
    "\n",
    "**Hinweis**:\n",
    "Aufgrund der Prüfung auf die `fivefold repetition`-Regel (durch die Funktion `maybe_repetitions`) ist der hier implementierte Minimax-Algorithmus nicht nur von dem aktuellen Board (FEN), sondern auch von den bereits gespielten Zügen (Stack) abhängig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI): # type: ignore\n",
    "    LIMIT = 99999\n",
    "\n",
    "    def minimax(self, board: chess.Board, depth: int) -> tuple[int, chess.Move | None]:\n",
    "        \"\"\"Searches the best value with given depth using minimax algorithm\"\"\"\n",
    "        best_move = None\n",
    "\n",
    "        if board.is_checkmate() and not board.turn:\n",
    "            # White has won the game\n",
    "            return self.LIMIT, None\n",
    "        elif board.is_checkmate() and board.turn:\n",
    "            # Black has won the game\n",
    "            return -self.LIMIT, None\n",
    "        # Check if game is over\n",
    "        elif board.is_insufficient_material() or not board.legal_moves or board.is_fifty_moves() or self.maybe_repetitions(board) > 4:\n",
    "            # Game is very likely a draw\n",
    "            return 0, None\n",
    "\n",
    "        # Recursion abort case\n",
    "        if depth == 0:\n",
    "            return self.evaluate(board), None\n",
    "\n",
    "        # White to play (positive numbers are good)\n",
    "        if board.turn:\n",
    "            maxEvaluation = -self.LIMIT\n",
    "            for move in sorted(board.legal_moves, key=lambda move: move.uci()):\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(board, depth - 1)\n",
    "                board.pop()\n",
    "                if depth == self.DEPTH and evaluation >= maxEvaluation:\n",
    "                    best_move = move\n",
    "                maxEvaluation = max(maxEvaluation, evaluation)\n",
    "            return maxEvaluation, best_move\n",
    "\n",
    "        # Black to play (negative numbers are good)\n",
    "        else:\n",
    "            minEvaluation = self.LIMIT\n",
    "            for move in sorted(board.legal_moves, key=lambda move: move.uci()):\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(board, depth - 1)\n",
    "                board.pop()\n",
    "                if depth == self.DEPTH and evaluation <= minEvaluation:\n",
    "                    best_move = move\n",
    "                minEvaluation = min(minEvaluation, evaluation)\n",
    "            return minEvaluation, best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berechnung des besten Zuges\n",
    "\n",
    "Die Funktion `get_next_middle_game_move` berechnet auf einem gegebenen Board den besten nächsten Zug. Dabei wird jeder mögliche Zug mithilfe der `minimax`-Funktion in der gewünschten Tiefe evaluiert und der Zug mit der besten Bewertung zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI): # type: ignore\n",
    "    def get_next_middle_game_move(self, board: chess.Board) -> chess.Move | None:\n",
    "        \"\"\"Gets the best next move\"\"\"\n",
    "        _, best_move = self.minimax(board, self.DEPTH)\n",
    "        return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Bereich\n",
    "\n",
    "Die folgenden Zellen enthalten Code zum Testen der oben implementierten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI): # type: ignore\n",
    "    def get_next_middle_game_move_debug(self, board: chess.Board) -> chess.Move | None:\n",
    "        \"\"\"Debugging version of get_next_middle_game_move: saves move path of best result\"\"\"\n",
    "        if board.is_game_over():\n",
    "            return None\n",
    "        # Debugging start\n",
    "        Exercise02AI.path_history = {}\n",
    "        # Debugging end\n",
    "        best_move_val = -self.LIMIT if board.turn else self.LIMIT\n",
    "        final_move = None\n",
    "\n",
    "        for move in sorted(board.legal_moves, key=lambda move: move.uci()):\n",
    "            board.push(move)\n",
    "            move_val = self.minimax_debug(board, self.DEPTH)\n",
    "            # IF best value <= current value AND white to play OR best value >= current value AND black to play\n",
    "            if (move_val <= best_move_val) and board.turn or (move_val >= best_move_val) and not board.turn:\n",
    "                best_move_val = move_val\n",
    "                final_move = move\n",
    "            board.pop()\n",
    "        return final_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging start\n",
    "from copy import deepcopy\n",
    "# Debugging end\n",
    "class Exercise02AI(Exercise02AI): # type: ignore\n",
    "    LIMIT = 99999\n",
    "\n",
    "    # Debugging start\n",
    "    path_history: dict = {}\n",
    "    # Debugging end\n",
    "\n",
    "    def minimax_debug(self, board: chess.Board, depth: int) -> int:\n",
    "        \"\"\"Debugging version of minimax: saves move path of best result\"\"\"\n",
    "        if board.is_checkmate() and not board.turn:\n",
    "            # White has won the game\n",
    "            return self.LIMIT\n",
    "        elif board.is_checkmate() and board.turn:\n",
    "            # Black has won the game\n",
    "            return -self.LIMIT\n",
    "        # Check if game is over\n",
    "        elif board.is_insufficient_material() or not board.legal_moves or board.is_fifty_moves() or self.maybe_repetitions(board) > 4:\n",
    "            # Game is very likely a draw\n",
    "            return 0\n",
    "\n",
    "        # Recursion abort case\n",
    "        if depth == 0:\n",
    "            return self.evaluate(board)\n",
    "\n",
    "        # White to play (positive numbers are good)\n",
    "        if board.turn:\n",
    "            maxEvaluation = -self.LIMIT\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                evaluation = self.minimax_debug(board, depth - 1)\n",
    "                # Debugging start\n",
    "                if maxEvaluation <= evaluation:\n",
    "                    board_copy = deepcopy(board)\n",
    "                    board_copy.pop()\n",
    "                    Exercise02AI.path_history[str(board_copy) + str(depth)] = move\n",
    "                # Debugging end\n",
    "                board.pop()\n",
    "                maxEvaluation = max(maxEvaluation, evaluation)\n",
    "            return maxEvaluation\n",
    "\n",
    "        # Black to play (negative numbers are good)\n",
    "        else:\n",
    "            minEvaluation = self.LIMIT\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                evaluation = self.minimax_debug(board, depth - 1)\n",
    "                # Debugging start\n",
    "                if minEvaluation >= evaluation:\n",
    "                    board_copy = deepcopy(board)\n",
    "                    board_copy.pop()\n",
    "                    Exercise02AI.path_history[str(board_copy) + str(depth)] = move\n",
    "                # Debugging end\n",
    "                board.pop()\n",
    "                minEvaluation = min(minEvaluation, evaluation)\n",
    "            return minEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging function\n",
    "from IPython.display import display\n",
    "def display_path(board_orig, move, depth):\n",
    "    \"\"\"Displays the move path to the best evaluation.\"\"\"\n",
    "    board = deepcopy(board_orig)\n",
    "    display(board)\n",
    "    board.push(move)\n",
    "    display(board)\n",
    "    for i in range(depth, 0, -1):\n",
    "        move = Exercise02AI.path_history[str(board) + str(i)]\n",
    "        board.push(move)\n",
    "        display(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluate\n",
    "board = chess.Board()\n",
    "board.set_fen(\"4k3/8/2n5/7K/5q2/2N5/8/2B5 b - - 0 1\")\n",
    "board.push(list(board.legal_moves)[0])\n",
    "player = Exercise02AI(\"Testplayer\", 3)\n",
    "player.evaluate(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluate\n",
    "board = chess.Board(\"4k3/5p2/8/6P1/8/8/8/4K3 b - - 0 1\")\n",
    "board.push(chess.Move.from_uci('f7f5')) # two square pawn move\n",
    "board.push(chess.Move.from_uci('g5f6')) # en passant capture\n",
    "player = Exercise02AI(\"Testplayer\", 3)\n",
    "player.evaluate(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Test get_next_middle_game_move\n",
    "DEPTH = 2\n",
    "board = chess.Board()\n",
    "board.set_fen(\"4k3/8/2n5/7K/5q2/2N5/8/2B5 b - - 0 1\")\n",
    "player = Exercise02AI(\"Testplayer\", DEPTH)\n",
    "#print(player.minimax(board, DEPTH))\n",
    "move = player.get_next_middle_game_move(board)\n",
    "print(move)\n",
    "#display_path(board, move, DEPTH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
