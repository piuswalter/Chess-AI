{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".container {\n",
    "  width: 100%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from AIBaseClass import ChessAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 02: Minimax (einfacher Materialwert)\n",
    "\n",
    "Dieses Notebook implementiert den Minimax-Algorithmus zur Berechnung des nächsten Zuges im Mittelspiel. Die Evaluierung eines Boards wird dabei durch Betrachtung des reinen Materialwertes der Figuren realisiert.\n",
    "\n",
    "Die Klasse wird um eine neue Konstante `DEPTH` erweitert. Diese gibt an, wie viele zukünftige Halbzüge bei der Berechnung des nächsten Zuges betrachtet werden sollen, das heißt, welche Tiefe der entsprechende Baum aller möglichen nächsten Halbzüge aufweist. Die Konstante wird als Parameter übergeben und im Konstruktor gesetzt.\n",
    "\n",
    "Ferner wird die Variable `last_evaluation` hinzugefügt, die den Wert der letzten Evaluierung auf Instanz-Ebene speichert. Die Funktion `reset` dient dazu, die Instanz nach einem beendeten Spiel in ihren Ursprungszustand zurückzusetzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import os\n",
    "\n",
    "\n",
    "class Exercise02AI(ChessAI):\n",
    "    \"\"\"Chooses middle game moves using minimax algorithm and material values.\"\"\"\n",
    "\n",
    "    def __init__(self, search_depth: int = 3, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.DEPTH = search_depth\n",
    "        self.last_evaluation: int | None = None\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets all internal variables.\"\"\"\n",
    "        super().reset()\n",
    "        self.last_evaluation = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierungsfunktion\n",
    "\n",
    "Die Evaluierungsfunktion `evaluate` nimmt ein Board als Argument und berechnet eine Ganzzahl als Maß dafür, ob die gegebene Stellung für den weißen Spieler eher zu einem Sieg (positiver Wert) oder zu einer Niederlage (negativer Wert) führt.\n",
    "\n",
    "Diese Implementierung verwendet dafür den einfachen Materialwert (Tauschwert in Bauerneinheiten) nach folgender Tabelle beschrieben in [8]:\n",
    "\n",
    "| Figurname  | Materialwert |\n",
    "|---|---|\n",
    "| Bauer (pawn) | 1  |\n",
    "| Springer (knight) | 3  |\n",
    "| Läufer (bishop) | 3  |\n",
    "| Turm (rook) | 5  |\n",
    "| Dame (queen) | 9  |\n",
    "\n",
    "Für die Berechnung des nächsten Schrittes stehen mehrere Funktionen zur Verfügung:\n",
    "\n",
    "- `full_evaluate`\n",
    "- `incremental_evaluate`\n",
    "- `evaluate`\n",
    "\n",
    "Die Funktion `full_evaluate` berechnet den Wert eines Boards (`board`) von Grund auf neu und geht dabei wie folgt vor:\n",
    "\n",
    "1. Es wird für jede Figur und für jede Farbe die Anzahl der Spielfiguren ermittelt.\n",
    "2. Für jede Figur wird die Differenz der Anzahl pro Farbe gebildet ($\\textrm{Weiß} - \\textrm{Schwarz}$).\n",
    "3. Jede Differenz wird mit dem figurenspezifischen Faktor multipliziert und zur Gesamtsumme addiert.\n",
    "\n",
    "Die Funktion `incremental_evaluate` berechnet die Änderungen der Bewertung, wenn der gegebene Zug (`next_move`) auf das übergebene Board (`board`) angewendet wird. Diese Änderung wird zurückgegeben. Hierfür werden die drei Fälle untersucht in denen sich der Wert verändert haben kann:\n",
    "\n",
    "1. Ein En Passant Zug wurde durchgeführt.\n",
    "2. Eine Figur wurde geschlagen.\n",
    "3. Ein Bauer wurde in eine neue Figur umgewandelt.\n",
    "\n",
    "Die Funktion `evaluate` bekommt ein Board (`board`) und die Evaluierung dieses Boards *vor* dem letzten Halbzug (`last_evaluation`) und gibt die Summe der letzten Evaluierung und der berechneten Änderung für den letzten Zug zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI):  # type: ignore\n",
    "    MATERIAL_VALUES = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 9,\n",
    "    }\n",
    "\n",
    "    def full_evaluate(self, board: chess.Board) -> int:\n",
    "        \"\"\"Returns a full evaluation of the given board.\"\"\"\n",
    "        evaluation = 0\n",
    "        for piece_type in chess.PIECE_TYPES[:-1]:\n",
    "            # Get the amount of pieces on the board per color\n",
    "            amount_type_white = len(board.pieces(piece_type, chess.WHITE))\n",
    "            amount_type_black = len(board.pieces(piece_type, chess.BLACK))\n",
    "            # Get difference\n",
    "            diff = amount_type_white - amount_type_black\n",
    "            # Calculate material value\n",
    "            evaluation += self.MATERIAL_VALUES[piece_type] * diff\n",
    "        return evaluation\n",
    "\n",
    "    def incremental_evaluate(\n",
    "        self, board: chess.Board, last_evaluation: int, next_move: chess.Move\n",
    "    ) -> int:\n",
    "        \"\"\"Returns an incrementally calculated evaluation of the given board.\"\"\"\n",
    "        change = 0\n",
    "\n",
    "        if captured_piece_type := board.piece_type_at(next_move.to_square):\n",
    "            change += self.MATERIAL_VALUES[captured_piece_type]\n",
    "\n",
    "        if promotion_piece_type := next_move.promotion:\n",
    "            change += (\n",
    "                self.MATERIAL_VALUES[promotion_piece_type]\n",
    "                - self.MATERIAL_VALUES[chess.PAWN]\n",
    "            )\n",
    "\n",
    "        elif captured_piece_type is None and board.is_en_passant(next_move):\n",
    "            # If the first two cases didn't match, check for en passant move\n",
    "            change += self.MATERIAL_VALUES[chess.PAWN]\n",
    "\n",
    "        # Add to old evaluation if white to move, else subtract\n",
    "        factor = +1 if board.turn else -1\n",
    "        return last_evaluation + change * factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax\n",
    "\n",
    "Die rekursive `minimax`-Funktion betrachtet bei einem gegebenen Board alle möglichen Stellungen (Boards) nach einer gegebenen Anzahl von Halbzügen (Tiefe) und gibt die beste Evaluierung (`evaluate`-Funktion) für den aktuellen Spieler zurück. Hierfür bekommt die Funktion als Argumente das aktuelle Board (`board`), die Evaluierungstiefe in Halbzügen (`depth`) und die Evaluierung des übergebenen Boards (`current_evaluation`). Zurückgegeben wird ein Tupel bestehend aus der besten Evaluierung und des Halbzuges, der auf den Pfad zu dieser Evaluierung führt.\n",
    "\n",
    "Die Konstante `LIMIT` wird als obere (`+`) beziehungsweise untere (`-`) Schranke für den Vergleich innerhalb der ersten Iteration verwendet.\n",
    "\n",
    "Innerhalb der `minimax`-Funktion werden zwei Fälle unterschieden:\n",
    "\n",
    "1. Falls Weiß am Zug ist, wird jeder mögliche Zug rekursiv evaluiert und das Maximum der Ergebnisse zurückgegeben.\n",
    "2. Falls Schwarz am Zug ist, wird jeder mögliche Zug rekursiv evaluiert und das Minimum der Ergebnisse zurückgegeben.\n",
    "\n",
    "### Hilfsfunktionen\n",
    "\n",
    "Die Funktion `early_abort_evaluation` nimmt dieselben Argumente an, wie die zuvor beschriebene und wird zu Beginn der `minimax`-Funktion aufgerufen. Sie bricht mithilfe der folgenden Fallunterscheidung den Funktionsaufruf und damit die Rekursion ab:\n",
    "\n",
    "1. Das Spiel ist ein Remis: In diesem Fall wird 0 als Wert zurückgegeben. Der Zug welcher zu diesem Zustand führt wird also nur gewählt, sofern jeder andere Zug zu einem für die Seite schlechteren Wert (und somit eher zu einer Niederlage) führt.\n",
    "2. Weiß hat das Spiel gewonnen: Hier wird das positive Limit (`99999`) abzüglich der aktuellen Tiefe zurückgegeben, welches auf jeden Fall größer oder gleich dem Evaluierungswert aller anderen Züge ist. Weiß wird daher diesen (oder einen in dieser Hinsicht gleichwertigen) Zug wählen um das Spiel zu gewinnen, Schwarz versucht den Zug möglichst zu vermeiden.\n",
    "3. Schwarz hat das Spiel gewonnen: Das negative Limit (`-99999`) abzüglich der aktuellen Tiefe wird zurückgegeben. Dieses ist auf jeden Fall kleiner oder gleich dem Evaluierungswert aller anderen Züge. Schwarz wird daher diesen (oder einen in dieser Hinsicht gleichwertigen) Zug wählen um das Spiel zu gewinnen, Weiß versucht den Zug möglichst zu vermeiden.\n",
    "4. Zuletzt wird geprüft, ob die Tiefe Null ist. Auch dann wird die Rekursion beendet und die Auswertung des aktuellen Boards zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI):  # type: ignore\n",
    "    LIMIT = 99999\n",
    "\n",
    "    def minimax_early_abort(\n",
    "        self, board: chess.Board, depth: int, current_evaluation: int\n",
    "    ) -> int | None:\n",
    "        \"\"\"Returns an evaluation iff the minimax has an early exit condition. Returns none otherwise.\"\"\"\n",
    "        if (is_checkmate := board.is_checkmate()) and not board.turn:\n",
    "            # White has won the game\n",
    "            evaluation = self.LIMIT - (self.DEPTH - depth)\n",
    "            return evaluation\n",
    "\n",
    "        if is_checkmate and board.turn:\n",
    "            # Black has won the game\n",
    "            evaluation = -self.LIMIT + (self.DEPTH - depth)\n",
    "            return evaluation\n",
    "\n",
    "        if (\n",
    "            board.is_insufficient_material()\n",
    "            or not board.legal_moves\n",
    "            or board.is_fifty_moves()\n",
    "        ):\n",
    "            # Game is a draw\n",
    "            return 0\n",
    "\n",
    "        # Recursion abort case\n",
    "        if depth == 0:\n",
    "            return current_evaluation\n",
    "\n",
    "        return None\n",
    "\n",
    "    def minimax(\n",
    "        self, board: chess.Board, depth: int, current_evaluation: int\n",
    "    ) -> tuple[int, chess.Move | None]:\n",
    "        \"\"\"Searches the best value with given depth using minimax algorithm.\"\"\"\n",
    "        self.stats[-1][\"nodes\"] += 1\n",
    "        early_abort_evaluation = self.minimax_early_abort(\n",
    "            board, depth, current_evaluation\n",
    "        )\n",
    "        if early_abort_evaluation is not None:\n",
    "            return early_abort_evaluation, None\n",
    "\n",
    "        best_move = None\n",
    "\n",
    "        # White to play (positive numbers are good)\n",
    "        if board.turn:\n",
    "            maxEvaluation = -self.LIMIT\n",
    "            for move in board.legal_moves:\n",
    "                new_evaluation = self.incremental_evaluate(\n",
    "                    board, current_evaluation, move\n",
    "                )\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(board, depth - 1, new_evaluation)\n",
    "                board.pop()\n",
    "                if depth == self.DEPTH and evaluation > maxEvaluation:\n",
    "                    best_move = move\n",
    "                maxEvaluation = max(maxEvaluation, evaluation)\n",
    "            return maxEvaluation, best_move\n",
    "\n",
    "        # Black to play (negative numbers are good)\n",
    "        else:\n",
    "            minEvaluation = self.LIMIT\n",
    "            for move in board.legal_moves:\n",
    "                new_evaluation = self.incremental_evaluate(\n",
    "                    board, current_evaluation, move\n",
    "                )\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(board, depth - 1, new_evaluation)\n",
    "                board.pop()\n",
    "                if depth == self.DEPTH and evaluation < minEvaluation:\n",
    "                    best_move = move\n",
    "                minEvaluation = min(minEvaluation, evaluation)\n",
    "            return minEvaluation, best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berechnung des besten Zuges\n",
    "\n",
    "Die Funktion `get_next_middle_game_move` berechnet auf einem gegebenen Board den nächsten besten Zug. Dabei wird jeder mögliche Zug mithilfe der `minimax`-Funktion in der gewünschten Tiefe evaluiert und der Zug mit der besten Bewertung zurückgegeben. Zusätzlich wird die aktuelle Stellung evaluiert und das Ergebnis in der Variable `self.last_evaluation` gespeichert. Die Evaluierung erfolgt inkrementell:\n",
    "\n",
    "- Hat die Variable `self.last_evaluation` der Wert `None`, so wird eine vollständige Evaluierung durchgeführt und das Ergebnis als `current_evaluation` gespeichert.\n",
    "- Ist die letzte Evaluierung nicht `None`, so ist `current_evaluation` die Summe von `last_evaluation` und der Evaluierung des letzten gegnerischen Zuges.\n",
    "\n",
    "Final wird die Bewertung des gewählten Zuges auf `current_evaluation` addiert.\n",
    "\n",
    "Zuletzt werden in der Klassenvariable `self.stats` die aktuellen Spielmetriken gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI):  # type: ignore\n",
    "    def get_next_middle_game_move(self, board: chess.Board) -> chess.Move:\n",
    "        \"\"\"Gets the best next move.\"\"\"\n",
    "        self.last_evaluation: int | None  # type annotation for mypy\n",
    "        if self.last_evaluation is None:\n",
    "            current_evaluation = self.full_evaluate(board)\n",
    "        else:\n",
    "            # Get current evaluation (after opponent move)\n",
    "            last_move = board.pop()\n",
    "            current_evaluation = self.incremental_evaluate(board, self.last_evaluation, last_move)  # type: ignore\n",
    "            board.push(last_move)\n",
    "\n",
    "        # Call minimax and get best move\n",
    "        self.stats[-1][\"nodes\"] = 0\n",
    "        future_evaluation, best_move = self.minimax(\n",
    "            board, self.DEPTH, current_evaluation\n",
    "        )\n",
    "        # Debugging fail save\n",
    "        assert best_move, f\"\"\"\n",
    "        Best move is None with fen '{board.fen()}' at player {type(self).__name__}! \n",
    "        depth: {self.DEPTH}, last_eval: {self.last_evaluation}, current_evaluation: {current_evaluation},\n",
    "        is_king_engame: {getattr(self, 'is_king_endgame', \"N/A\")}, move_stack: {board.move_stack}\n",
    "        \"\"\"\n",
    "        # Update last evaluation (after player move)\n",
    "        self.last_evaluation = self.incremental_evaluate(\n",
    "            board, current_evaluation, best_move\n",
    "        )\n",
    "        # Update stats\n",
    "        self.stats[-1][\"minimax_eval\"] = future_evaluation\n",
    "        self.stats[-1][\"board_eval_before_move\"] = current_evaluation\n",
    "        self.stats[-1][\"board_eval_after_move\"] = self.last_evaluation\n",
    "        return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Bereich\n",
    "\n",
    "Die folgenden Zellen enthalten Unit-Tests der oben implementierten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create player and board\n",
    "unit_test_player = Exercise02AI(player_name=\"Ex02AI\", search_depth=3)\n",
    "board = chess.Board(\"5rk1/1b3p2/8/3p4/3p2P1/2Q4B/5P1K/R3R3 b - - 0 36\")\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test full evaluation\n",
    "def test_full_evaluation(unit_test_player: ChessAI, Board: chess.Board):\n",
    "    full_eval = unit_test_player.full_evaluate(board)\n",
    "    print(f\"Full Evaluation: {full_eval}\")\n",
    "    assert full_eval == 13, \"Full evaluation does not match expected value!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_evaluation(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test incremental evaluation\n",
    "def test_incremental_evaluation(unit_test_player: ChessAI, board: chess.Board):\n",
    "    next_move = chess.Move.from_uci(\"d4c3\")  # white queen capture\n",
    "    inc_eval = unit_test_player.incremental_evaluate(board, 0, next_move)\n",
    "    print(f\"Incremental Evaluation: {inc_eval}\")\n",
    "    assert inc_eval == -9, \"Incremental evaluation does not match expected value!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_incremental_evaluation(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation\n",
    "def test_evaluation(unit_test_player: ChessAI, board: chess.Board):\n",
    "    next_move = chess.Move.from_uci(\"d4c3\")  # white queen capture\n",
    "    full_eval, inc_eval = 13, -9\n",
    "    evaluation = unit_test_player.incremental_evaluate(board, full_eval, next_move)\n",
    "    board.push(next_move)\n",
    "    new_full_eval = unit_test_player.full_evaluate(board)\n",
    "    board.pop()\n",
    "    print(f\"Full Evaluation: {full_eval}\")\n",
    "    print(f\"Incremental Evaluation: {inc_eval}\")\n",
    "    print(f\"Evaluation: {evaluation}\")\n",
    "    print(f\"New Full Evaluation: {new_full_eval}\")\n",
    "    assert new_full_eval == evaluation, \"Incremental and full evaluation are different!\"\n",
    "    assert evaluation == full_eval + inc_eval, \"Evaluation does not match expected sum!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluation(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test minimax\n",
    "def test_minimax(\n",
    "    unit_test_player: ChessAI,\n",
    "    board: chess.Board,\n",
    "    current_evaluation: int,\n",
    "    expected_evaluation: int,\n",
    "    expected_move: str,\n",
    "    expected_nodes: int,\n",
    "):\n",
    "    unit_test_player.stats[-1][\"nodes\"] = 0\n",
    "    mm_evaluation, mm_move = unit_test_player.minimax(\n",
    "        board, unit_test_player.DEPTH, current_evaluation\n",
    "    )\n",
    "    nodes = unit_test_player.stats[-1][\"nodes\"]\n",
    "    print(f\"Minimax Evaluation: {mm_evaluation}\")\n",
    "    print(f\"Minimax Move: {mm_move}\")\n",
    "    print(f\"Nodes searched: {nodes}\")\n",
    "    assert (\n",
    "        mm_evaluation == expected_evaluation\n",
    "    ), \"Minimax evaluation does not match expected value!\"\n",
    "    assert mm_move.uci() == expected_move, \"Minimax move does not match expected value!\"\n",
    "    assert nodes == expected_nodes, \"Searched node count has changed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_minimax(\n",
    "    unit_test_player,\n",
    "    board,\n",
    "    current_evaluation=4,\n",
    "    expected_evaluation=-5,\n",
    "    expected_move=\"d4c3\",\n",
    "    expected_nodes=14377,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test next move function\n",
    "def test_next_move(\n",
    "    unit_test_player: ChessAI,\n",
    "    board: chess.Board,\n",
    "    expected_move: str,\n",
    "    expected_nodes: int,\n",
    "):\n",
    "    unit_test_player.stats[-1][\"nodes\"] = 0\n",
    "    unit_test_player.last_evaluation = None\n",
    "    move = unit_test_player.get_next_middle_game_move(board)\n",
    "    nodes = unit_test_player.stats[-1][\"nodes\"]\n",
    "    print(f\"Move: {move}\")\n",
    "    print(f\"Nodes searched: {nodes}\")\n",
    "    assert move.uci() == expected_move, \"Next move does not match expected value!\"\n",
    "    assert nodes == expected_nodes, \"Searched node count has changed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_next_move(\n",
    "    unit_test_player,\n",
    "    board,\n",
    "    expected_move=\"d4c3\",\n",
    "    expected_nodes=14377,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reset function\n",
    "def test_reset(unit_test_player: ChessAI, _: chess.Board):\n",
    "    unit_test_player.reset()\n",
    "    assert unit_test_player.last_evaluation is None, \"Reset was not successful!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reset(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporärer Bereich\n",
    "\n",
    "Der folgende Bereich dient zum temporären Debuggen und kann nicht-funktionierenden Code enthalten. Dieser Bereich wird vor der Abgabe entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
