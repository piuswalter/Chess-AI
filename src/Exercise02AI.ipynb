{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".container {\n",
    "  width: 100%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from AIBaseClass import ChessAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 02: Minimax (einfacher Materialwert)\n",
    "\n",
    "Dieses Notebook implementiert den Minimax-Algorithmus zur Berechnung des nächsten Zuges im Mittelspiel. Die Evaluierung eines Boards wird dabei durch Betrachtung des reinen Materialwertes der Figuren realisiert.\n",
    "\n",
    "Die Klasse wird um eine neue Konstante `DEPTH` erweitert. Diese gibt an, wie viele zukünftige Halbzüge bei der Berechnung des nächsten Zuges betrachtet werden sollen, das heißt, welche Höhe der entsprechende Baum aller möglichen nächsten Halbzüge aufweist. Die Konstante wird als Parameter übergeben und im Konstruktor gesetzt.\n",
    "\n",
    "Ferner wird die Variable `last_evaluation` hinzugefügt, die den Wert der letzten Evaluierung auf Instanz-Ebene speichert. Die Funktion `reset` dient dazu, die Instanz nach einem beendeten Spiel in ihren Ursprungszustand zurückzusetzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess_custom as chess\n",
    "import os\n",
    "\n",
    "\n",
    "class Exercise02AI(ChessAI):\n",
    "    \"\"\"Chooses middle game moves using minimax algorithm and material values\"\"\"\n",
    "\n",
    "    def __init__(self, search_depth: int = 3, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.DEPTH = search_depth\n",
    "        self.last_evaluation: int | None = None\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets all internal variables\"\"\"\n",
    "        super().reset()\n",
    "        self.last_evaluation = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierungsfunktion\n",
    "\n",
    "Die Evaluierungsfunktion `evaluate` nimmt ein Board als Argument und berechnet eine Ganzzahl als Maß dafür, ob die gegebene Stellung für den weißen Spieler eher zu einem Sieg (positiver Wert) oder zu einer Niederlage (negativer Wert) führt.\n",
    "\n",
    "Diese Implementierung verwendet dafür den Materialwert (Tauschwert in Bauerneinheiten) nach folgender Tabelle:\n",
    "\n",
    "| Figurname  | Materialwert |\n",
    "|---|---|\n",
    "| Bauer (pawn) | 1  |\n",
    "| Springer (knight) | 3  |\n",
    "| Läufer (bishop) | 3  |\n",
    "| Turm (rook) | 5  |\n",
    "| Dame (queen) | 9  |\n",
    "| König (king) | 20000 |\n",
    "\n",
    "Für die Berechnung des nächsten Schrittes stehen mehrere Funktionen zur Verfügung:\n",
    "\n",
    "- `full_evaluate`\n",
    "- `incremental_evaluate`\n",
    "- `evaluate`\n",
    "\n",
    "Die Funktion `full_evaluate` berechnet den Wert eines Boards (`board`) von Grund auf neu und geht dabei wie folgt vor:\n",
    "\n",
    "1. Es wird für jede Figur und für jede Farbe die Anzahl der Spielfiguren ermittelt.\n",
    "2. Für jede Figur wird die Differenz der Anzahl pro Farbe gebildet ($\\texttt{Weiß} - \\texttt{Schwarz}$)\n",
    "3. Jede Differenz wird mit dem figurenspezifischen Faktor multipliziert und zur Gesamtsumme addiert.\n",
    "\n",
    "Die Funktion `incremental_evaluate` berechnet die Änderungen der Bewertung, wenn der gegebene Zug (`next_move`) auf das übergebene Board (`board`) angewendet wird. Diese Änderung wird zurückgegeben. Hierfür werden die drei Fälle untersucht in denen sich der Wert verändert haben kann:\n",
    "\n",
    "1. Ein En Passant Zug wurde durchgeführt\n",
    "2. Eine Figur wurde geschlagen\n",
    "3. Ein Bauer wurde in eine neue Figur umgewandelt\n",
    "\n",
    "Die Funktion `evaluate` bekommt ein Board (`board`) und die Evaluierung dieses Boards *vor* dem letzten Halbzug (`last_evaluation`) und gibt die Summe der letzten Evaluierung und der berechneten Änderung für den letzten Zug zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI):  # type: ignore\n",
    "    MATERIAL_VALUES = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 9,\n",
    "        chess.KING: 20000,\n",
    "    }\n",
    "\n",
    "    def full_evaluate(self, board: chess.Board) -> int:\n",
    "        \"\"\"Returns a full evaluation of the given board.\"\"\"\n",
    "        evaluation = 0\n",
    "        for piece_type in chess.PIECE_TYPES:\n",
    "            # Get the amount of pieces on the board per color\n",
    "            amount_type_white = len(board.pieces(piece_type, chess.WHITE))\n",
    "            amount_type_black = len(board.pieces(piece_type, chess.BLACK))\n",
    "            # Get difference\n",
    "            diff = amount_type_white - amount_type_black\n",
    "            # Calculate material value\n",
    "            evaluation += self.MATERIAL_VALUES[piece_type] * diff\n",
    "        return evaluation\n",
    "\n",
    "    def incremental_evaluate(self, board: chess.Board, next_move: chess.Move) -> int:\n",
    "        \"\"\"Returns an incrementally calculated evaluation of the given board.\"\"\"\n",
    "        change = 0\n",
    "\n",
    "        if captured_piece_type := board.piece_type_at(next_move.to_square):\n",
    "            change += self.MATERIAL_VALUES[captured_piece_type]\n",
    "\n",
    "        if promotion_piece_type := next_move.promotion:\n",
    "            change += (\n",
    "                self.MATERIAL_VALUES[promotion_piece_type]\n",
    "                - self.MATERIAL_VALUES[chess.PAWN]\n",
    "            )\n",
    "\n",
    "        elif captured_piece_type is None and board.is_en_passant(next_move):\n",
    "            # If the first two cases didn't match, check for en passant move\n",
    "            change += self.MATERIAL_VALUES[chess.PAWN]\n",
    "\n",
    "        # Add to old evaluation if white to move, else subtract\n",
    "        factor = +1 if board.turn else -1\n",
    "        return change * factor\n",
    "\n",
    "    def evaluate(self, board: chess.Board, last_evaluation: int) -> int:\n",
    "        \"\"\"Evaluates a given board.\n",
    "        Returns a positive value if white has a better material value than black.\"\"\"\n",
    "        # Incremental evaluation\n",
    "        last_move = board.pop()\n",
    "        evaluation = last_evaluation + self.incremental_evaluate(board, last_move)\n",
    "        board.push(last_move)\n",
    "        return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax\n",
    "\n",
    "Die rekursive `minimax`-Funktion betrachtet bei einem gegebenen Board alle möglichen Stellungen (Boards) nach einer gegebenen Anzahl von Halbzügen (Tiefe) und gibt die beste Evaluierung (`evaluate`-Funktion) für den aktuellen Spieler zurück. Hierfür bekommt die Funktion als Argumente das aktuelle Board (`board`), die Evaluierungstiefe in Halbzügen (`depth`) und die Evaluierung des übergebenen Boards (`current_evaluation`). Zurückgegeben wird ein Tupel bestehend aus der besten Evaluierung und des Halbzuges, der auf den Pfad zu dieser Evaluierung führt.\n",
    "\n",
    "Die Konstante `LIMIT` wird als obere (+) beziehungsweise untere (-) Schranke für den Vergleich innerhalb der ersten Iteration verwendet.\n",
    "\n",
    "Folgende Fälle werden unterschieden:\n",
    "\n",
    "1. Falls das Spiel beendet ist, werden die drei folgenden Möglichkeiten unterschieden:\n",
    "    - Das Spiel ist ein Remis:\n",
    "    In diesem Fall wird 0 als Wert zurückgegeben. Der Zug welcher zu diesem Zustand führt wird also nur gewählt, sofern jeder andere Zug zu einem für die Seite schlechteren Wert (und somit eher zu einer Niederlage) führt.\n",
    "    - Weiß hat das Spiel gewonnen:\n",
    "    Hier wird das positive Limit (`99999`) abzüglich der aktuellen Tiefe zurückgegeben, welches auf jeden Fall größer oder gleich dem Evaluierungswert aller anderen Züge ist. Weiß wird daher diesen (oder einen in dieser Hinsicht gleichwertigen) Zug wählen um das Spiel zu gewinnen, Schwarz versucht den Zug möglichst zu vermeiden.\n",
    "    - Schwarz hat das Spiel gewonnen:\n",
    "    Das negative Limit (`-99999`) abzüglich der aktuellen Tiefe wird zurückgegeben. Dieses ist auf jeden Fall kleiner oder gleich dem Evaluierungswert aller anderen Züge. Schwarz wird daher diesen (oder einen in dieser Hinsicht gleichwertigen) Zug wählen um das Spiel zu gewinnen, Weiß versucht den Zug möglichst zu vermeiden.\n",
    "2. Falls die Tiefe Null ist, wird die Auswertung des aktuellen Boards zurückgegeben (Rekursionsende).\n",
    "3. Falls Weiß am Zug ist, wird jeder mögliche Zug rekursiv evaluiert und das Maximum der Ergebnisse zurückgegeben.\n",
    "4. Falls Schwarz am Zug ist, wird jeder mögliche Zug rekursiv evaluiert und das Minimum der Ergebnisse zurückgegeben.\n",
    "\n",
    "**Hinweis**:\n",
    "Aufgrund der Prüfung auf die `fivefold repetition`-Regel (durch den Funktionsaufruf `board.is_repetition(5)`) ist der hier implementierte Minimax-Algorithmus nicht nur von dem aktuellen Board, sondern auch von den bereits gespielten Zügen (move stack) abhängig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Exercise02AI(Exercise02AI):  # type: ignore\n",
    "    LIMIT = 99999\n",
    "\n",
    "    def minimax_early_abort(\n",
    "        self, board: chess.Board, depth: int, current_evaluation: int\n",
    "    ) -> Union[int, None]:\n",
    "        \"\"\"Returns an evaluation iff the minimax has an early exit conditions. Returns none otherwise.\"\"\"\n",
    "        if (is_checkmate := board.is_checkmate()) and not board.turn:\n",
    "            # White has won the game\n",
    "            evaluation = self.LIMIT - (self.DEPTH - depth)\n",
    "            return evaluation\n",
    "\n",
    "        elif is_checkmate and board.turn:\n",
    "            # Black has won the game\n",
    "            evaluation = -self.LIMIT + (self.DEPTH - depth)\n",
    "            return evaluation\n",
    "\n",
    "        elif (\n",
    "            board.is_insufficient_material()\n",
    "            or not board.legal_moves\n",
    "            or board.is_fifty_moves()\n",
    "            or board.is_repetition(5)\n",
    "        ):\n",
    "            # Game is a draw\n",
    "            return 0\n",
    "\n",
    "        # Recursion abort case\n",
    "        if depth == 0:\n",
    "            return current_evaluation\n",
    "\n",
    "        return None\n",
    "\n",
    "    def minimax(\n",
    "        self, board: chess.Board, depth: int, current_evaluation: int\n",
    "    ) -> tuple[int, chess.Move]:\n",
    "        \"\"\"Searches the best value with given depth using minimax algorithm\"\"\"\n",
    "        early_abort_evaluation = self.minimax_early_abort(\n",
    "            board, depth, current_evaluation\n",
    "        )\n",
    "        if early_abort_evaluation is not None:\n",
    "            return early_abort_evaluation, None\n",
    "\n",
    "        best_move = None\n",
    "\n",
    "        # White to play (positive numbers are good)\n",
    "        if board.turn:\n",
    "            maxEvaluation = -self.LIMIT\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(\n",
    "                    board, depth - 1, self.evaluate(board, current_evaluation)\n",
    "                )\n",
    "                board.pop()\n",
    "                if depth == self.DEPTH and evaluation > maxEvaluation:\n",
    "                    best_move = move\n",
    "                maxEvaluation = max(maxEvaluation, evaluation)\n",
    "            return maxEvaluation, best_move\n",
    "\n",
    "        # Black to play (negative numbers are good)\n",
    "        else:\n",
    "            minEvaluation = self.LIMIT\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(\n",
    "                    board, depth - 1, self.evaluate(board, current_evaluation)\n",
    "                )\n",
    "                board.pop()\n",
    "                if depth == self.DEPTH and evaluation < minEvaluation:\n",
    "                    best_move = move\n",
    "                minEvaluation = min(minEvaluation, evaluation)\n",
    "            return minEvaluation, best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berechnung des besten Zuges\n",
    "\n",
    "Die Funktion `get_next_middle_game_move` berechnet auf einem gegebenen Board den besten nächsten Zug. Dabei wird jeder mögliche Zug mithilfe der `minimax`-Funktion in der gewünschten Tiefe evaluiert und der Zug mit der besten Bewertung zurückgegeben. Zusätzlich wird die aktuelle Stellung evaluiert und das Ergebnis in der Variable `self.last_evaluation` gespeichert. Die Evaluierung erfolgt inkrementell:\n",
    "- Ist die Variable `self.last_evaluation` `None`, so wird eine vollständige Evaluierung durchgeführt und das Ergebnis als `current_evaluation` gespeichert\n",
    "- Ist die letzte Evaluierung nicht `None`, so ist `current_evaluation` die Summe von `last_evaluation` und der Evaluierung des letzten gegnerischen Zuges.\n",
    "\n",
    "Final wird die Bewertung des gewählten Zuges auf `current_evaluation` addiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI):  # type: ignore\n",
    "    def get_next_middle_game_move(self, board: chess.Board) -> chess.Move:\n",
    "        \"\"\"Gets the best next move\"\"\"\n",
    "        self.last_evaluation: int | None  # type annotation for mypy\n",
    "        if self.last_evaluation is None:\n",
    "            current_evaluation = self.full_evaluate(board)\n",
    "        else:\n",
    "            # Get current evaluation (after opponent move)\n",
    "            current_evaluation = self.evaluate(board, self.last_evaluation)  # type: ignore\n",
    "\n",
    "        # Call minimax and get best move\n",
    "        _, best_move = self.minimax(board, self.DEPTH, current_evaluation)\n",
    "        # Debugging fail save\n",
    "        assert best_move, f\"\"\"\n",
    "        Best move is None with fen '{board.fen()}' at player {type(self).__name__}! \n",
    "        depth: {self.DEPTH}, last_eval: {self.last_evaluation}, current_evaluation: {current_evaluation},\n",
    "        is_king_engame: {getattr(self, 'is_king_endgame', \"N/A\")}, move_stack: {board.move_stack}\n",
    "        \"\"\"\n",
    "        # Update last evaluation (after player move)\n",
    "        self.last_evaluation = current_evaluation + self.incremental_evaluate(\n",
    "            board, best_move\n",
    "        )\n",
    "        return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Bereich\n",
    "\n",
    "Die folgenden Zellen enthalten Unit-Tests der oben implementierten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create player and board\n",
    "unit_test_player = Exercise02AI(player_name=\"Ex02AI\", search_depth=2)\n",
    "board = chess.Board(\"5rk1/1b3p2/8/3p4/3p2P1/2Q4B/5P1K/R3R3 b - - 0 36\")\n",
    "next_move = chess.Move.from_uci(\"d4c3\")  # white queen capture\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test full evaluation\n",
    "def test_full_evaluation(unit_test_player: ChessAI, Board: chess.Board):\n",
    "    full_eval = unit_test_player.full_evaluate(board)\n",
    "    assert full_eval == 13, \"Full evaluation does not match expected value!\"\n",
    "    full_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_evaluation(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test incremental evaluation\n",
    "def test_incremental_evaluation(unit_test_player: ChessAI, board: chess.Board):\n",
    "    inc_eval = unit_test_player.incremental_evaluate(board, next_move)\n",
    "    assert inc_eval == -9, \"Incremental evaluation does not match expected value!\"\n",
    "    inc_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_incremental_evaluation(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation\n",
    "def test_evaluation(unit_test_player: ChessAI, board: chess.Board):\n",
    "    board.push(next_move)\n",
    "    full_eval, inc_eval = 13, -9\n",
    "    evaluation = unit_test_player.evaluate(board, last_evaluation=full_eval)\n",
    "    assert evaluation == full_eval + inc_eval, \"Evaluation does not match expected sum!\"\n",
    "    new_full_eval = unit_test_player.full_evaluate(board)\n",
    "    assert new_full_eval == evaluation, \"Incremental and full evaluation are different!\"\n",
    "    board.pop()\n",
    "    print(f\"Full Evaluation: {full_eval}\")\n",
    "    print(f\"Incremental Evaluation: {inc_eval}\")\n",
    "    print(f\"Evaluation: {evaluation}\")\n",
    "    print(f\"New Full Evaluation: {new_full_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluation(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test minimax\n",
    "def test_minimax(unit_test_player: ChessAI, board: chess.Board):\n",
    "    board.push(next_move)\n",
    "    mm_evaluation, mm_move = unit_test_player.minimax(\n",
    "        board, depth=2, current_evaluation=4\n",
    "    )\n",
    "    assert mm_evaluation == 4, \"Minimax evaluation does not match expected value!\"\n",
    "    assert mm_move.uci() == \"h3g2\", \"Minimax move does not match expected value!\"\n",
    "    board.pop()\n",
    "    print(f\"Minimax Evaluation {mm_evaluation}\")\n",
    "    print(f\"Minimax Move {mm_move}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_minimax(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test next move function\n",
    "def test_next_move(unit_test_player: ChessAI, board: chess.Board):\n",
    "    board.push(next_move)\n",
    "    move = unit_test_player.get_next_middle_game_move(board)\n",
    "    assert move.uci() == \"h3g2\", \"Next move does not match expected value!\"\n",
    "    board.pop()\n",
    "    print(f\"Move: {move}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_next_move(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reset function\n",
    "def test_reset(unit_test_player: ChessAI, _: chess.Board):\n",
    "    unit_test_player.reset()\n",
    "    assert unit_test_player.last_evaluation is None, \"Reset was not successful!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reset(unit_test_player, board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporärer Bereich\n",
    "\n",
    "Der folgende Bereich dient zum temporären Debuggen und kann nicht-funktionierenden Code enthalten. Dieser Bereich wird vor der Abgabe entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
