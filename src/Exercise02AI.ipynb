{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".container {\n",
    "  width: 100%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from AIBaseClass import ChessAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 02: Minimax (einfacher Materialwert)\n",
    "\n",
    "Diese Klasse implementiert den Minimax-Algorithmus zur Berechnung des nächsten Zuges im Mittelspiel. Die Evaluierung eines Boards wird dabei durch Betrachtung des Materialwertes der Figuren realisiert.\n",
    "\n",
    "Die Klasse wird um eine neue Konstante `DEPTH` erweitert. Diese gibt an, wie viele zukünftige Halbzüge bei der Berechnung des nächsten Zuges betrachtet werden sollen, das heißt, welche Höhe der entsprechende Baum aller möglichen nächsten Halbzüge aufweist. Die Konstante wird als Parameter übergeben und im Konstruktor gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess_custom as chess\n",
    "import os\n",
    "\n",
    "class Exercise02AI(ChessAI):\n",
    "    \"\"\"Chooses middle game moves using minimax algorithm and material values\"\"\"\n",
    "\n",
    "    def __init__(self, player_name: str, search_depth: int = 3) -> None:\n",
    "        super().__init__(player_name)\n",
    "        self.DEPTH = int(os.environ.get(\"depth\", search_depth))\n",
    "        self.last_evaluation: int | None = None\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets all internal variables\"\"\"\n",
    "        super().reset()\n",
    "        self.last_evaluation = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierungsfunktion\n",
    "\n",
    "Die Evaluierungsfunktion `evaluate` nimmt ein Board als Argument und berechnet eine Ganzzahl als Maß dafür, ob die gegebene Stellung für den weißen Spieler eher zu einem Sieg (positiver Wert) oder zu einer Niederlage (negativer Wert) führt.\n",
    "\n",
    "Diese Implementierung verwendet dafür den Materialwert (Tauschwert in Bauerneinheiten) nach folgender Tabelle:\n",
    "\n",
    "| Figurname  | Materialwert |\n",
    "|---|---|\n",
    "| Bauer (pawn) | 1  |\n",
    "| Springer (knight) | 3  |\n",
    "| Läufer (bishop) | 3  |\n",
    "| Turm (rook) | 5  |\n",
    "| Dame (queen) | 9  |\n",
    "| König (king) | 20000 |\n",
    "\n",
    "Für die Berechnung des nächsten Schrittes stehen mehrere Funktionen zur Verfügung:\n",
    "\n",
    "- `full_evaluate`\n",
    "- `incremental_evaluate`\n",
    "- `evaluate`\n",
    "\n",
    "Die Funktion `full_evaluate` berechnet den Wert eines Boards von Grund auf neu und geht dabei wie folgt vor:\n",
    "\n",
    "1. Es wird für jede Figur und für jede Farbe die Anzahl der Spielfiguren ermittelt.\n",
    "2. Für jede Figur wird die Differenz der Anzahl pro Farbe gebildet ($\\texttt{Weiß} - \\texttt{Schwarz}$)\n",
    "3. Jede Differenz wird mit dem figurenspezifischen Faktor multipliziert und zur Gesamtsumme addiert.\n",
    "\n",
    "Die Funktion `incremental_evaluate` berechnet die Änderungen der Bewertung wenn der gegebene Zug auf dem übergebenen Board ausgeführt wird und gibt diese Änderung zurück. Hierfür werden die drei Fälle untersucht in denen sich der Wert verändert haben kann:\n",
    "\n",
    "1. Ein En Passant Zug wurde durchgeführt\n",
    "2. Eine Figur wurde geschlagen\n",
    "3. Ein Bauer wurde in eine neue Figur umgewandelt\n",
    "\n",
    "Die Funktion `evaluate` speichert den Rückgabewert der inkrementellen Berechnung im Cache und gibt ihn anschließend zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI): # type: ignore\n",
    "    MATERIAL_VALUES = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 9,\n",
    "        chess.KING: 20000\n",
    "    }\n",
    "\n",
    "    def full_evaluate(self, board: chess.Board) -> int:\n",
    "        \"\"\"Returns a full evaluation of the given board.\"\"\"\n",
    "        evaluation = 0\n",
    "        for piece_type in chess.PIECE_TYPES:\n",
    "            # Get the amount of pieces on the board per color\n",
    "            amount_type_white   = len(board.pieces(piece_type,   chess.WHITE))\n",
    "            amount_type_black   = len(board.pieces(piece_type,   chess.BLACK))\n",
    "            # Get difference\n",
    "            diff = amount_type_white - amount_type_black\n",
    "            # Calculate material value\n",
    "            evaluation += self.MATERIAL_VALUES[piece_type] * diff\n",
    "        return evaluation\n",
    "\n",
    "    def incremental_evaluate(self, board: chess.Board, last_move: chess.Move) -> int:\n",
    "        \"\"\"Returns an incrementally calculated evaluation of the given board.\"\"\"\n",
    "        change = 0\n",
    "\n",
    "        if captured_piece_type := board.piece_type_at(last_move.to_square):\n",
    "            change += self.MATERIAL_VALUES[captured_piece_type]\n",
    "\n",
    "        if promotion_piece_type := last_move.promotion:\n",
    "            change += self.MATERIAL_VALUES[promotion_piece_type] - self.MATERIAL_VALUES[chess.PAWN]\n",
    "            \n",
    "        elif captured_piece_type is None and board.is_en_passant(last_move):\n",
    "            # If the first two cases didn't match, check for en passant move\n",
    "            change += self.MATERIAL_VALUES[chess.PAWN]\n",
    "        \n",
    "        # Add to old evaluation if white to move, else subtract\n",
    "        factor = +1 if board.turn else -1\n",
    "        return change * factor\n",
    "\n",
    "    def evaluate(self, board: chess.Board, last_move: chess.Move, last_evaluation: int) -> int:\n",
    "        \"\"\"Evaluates a given board. \n",
    "        Returns a positive value if white has a better material value than black.\"\"\"\n",
    "        return last_evaluation + self.incremental_evaluate(board, last_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fünffache Stellungswiederholung\n",
    "\n",
    "Im Schach besagt die `fivefold repetition`-Regel, dass ein Spiel sofort als Remis gewertet wird, falls sich eine Stellung zum fünften Mal wiederholt. Zwei Stellungen gelten dabei als gleich g. d. w. die Boardbelegung (Farbe, Figurtyp, Position) und die möglichen Züge dieselben sind.\n",
    "Die Prüfung auf eine Stellungswiederholung ist in der `chess`-Bibliothek sehr langsam, da im schlechtesten Fall das gesamte Spiel neu durchlaufen wird (siehe Dokumentation). Die Funktion `repetitions` führt diese Prüfung effizienter mithilfe der Boardbelegung durch und gibt die Anzahl der Wiederholungen zurück. Diese Prüfung wird nur innerhalb des Minimax-Algorithmus verwendet, nach jedem abgeschlossenen Zug findet ein zusätzlicher Test mithilfe der `chess`-Bibliothek statt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax\n",
    "\n",
    "Die rekursive `minimax`-Funktion betrachtet bei einem gegebenen Board alle möglichen Stellungen (Boards) nach einer gegebenen Anzahl von Halbzügen (Tiefe) und gibt die beste Evaluierung (`evaluate`-Funktion) für den aktuellen Spieler zurück.\n",
    "\n",
    "Die Konstante `LIMIT` wird als obere (+) beziehungsweise untere (-) Schranke für den Vergleich innerhalb der ersten Iteration verwendet.\n",
    "\n",
    "Folgende Fälle werden unterschieden:\n",
    "\n",
    "1. Falls das Spiel beendet ist, werden die drei folgenden Möglichkeiten unterschieden:\n",
    "    - Das Spiel ist ein Remis:\n",
    "    In diesem Fall wird 0 als Wert zurückgegeben. Der Zug welcher zu diesem Zustand führt wird also nur gewählt, sofern jeder andere Zug zu einem für die Seite schlechteren Wert (und somit eher zu einer Niederlage) führt.\n",
    "    - Weiß hat das Spiel gewonnen:\n",
    "    Hier wird das positive Limit (`99999`) abzüglich der aktuellen Tiefe zurückgegeben, welches auf jeden Fall größer oder gleich dem Evaluierungswert aller anderen Züge ist. Weiß wird daher diesen (oder einen in dieser Hinsicht gleichwertigen) Zug wählen um das Spiel zu gewinnen, Schwarz versucht den Zug möglichst zu vermeiden.\n",
    "    - Schwarz hat das Spiel gewonnen:\n",
    "    Das negative Limit (`-99999`) abzüglich der aktuellen Tiefe wird zurückgegeben. Dieses ist auf jeden Fall kleiner oder gleich dem Evaluierungswert aller anderen Züge. Schwarz wird daher diesen (oder einen in dieser Hinsicht gleichwertigen) Zug wählen um das Spiel zu gewinnen, Weiß versucht den Zug möglichst zu vermeiden.\n",
    "2. Falls die Tiefe Null ist, wird die Auswertung des aktuellen Boards zurückgegeben (Rekursionsende).\n",
    "3. Falls die Tiefe Eins ist, wird eine vollständige Beurteilung des Boards erstellt und gespeichert. Auf diese Weise können auf der Tiefe 0 alle Bewertungen inkrementell erfolgen. In der Gesamtzahl sind damit ca. 97% aller Beurteilungen inkrementell.\n",
    "4. Falls Weiß am Zug ist, wird jeder mögliche Zug rekursiv evaluiert und das Maximum der Ergebnisse zurückgegeben.\n",
    "5. Falls Schwarz am Zug ist, wird jeder mögliche Zug rekursiv evaluiert und das Minimum der Ergebnisse zurückgegeben.\n",
    "\n",
    "**Hinweis**:\n",
    "Aufgrund der Prüfung auf die `fivefold repetition`-Regel (durch die Funktion `is_fivefold_repetition`) ist der hier implementierte Minimax-Algorithmus nicht nur von dem aktuellen Board (FEN), sondern auch von den bereits gespielten Zügen (Stack) abhängig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI): # type: ignore\n",
    "    LIMIT = 99999\n",
    "\n",
    "    def minimax(self, board: chess.Board, depth: int, current_evaluation: int) -> tuple[int, list[chess.Move]]:\n",
    "        \"\"\"Searches the best value with given depth using minimax algorithm\"\"\"\n",
    "        best_move = None\n",
    "        \n",
    "        if (is_checkmate := board.is_checkmate()) and not board.turn:\n",
    "            # White has won the game\n",
    "            evaluation = self.LIMIT - (self.DEPTH - depth)\n",
    "            return evaluation, None\n",
    "        elif is_checkmate and board.turn:\n",
    "            # Black has won the game\n",
    "            evaluation = -self.LIMIT + (self.DEPTH - depth)\n",
    "            return evaluation, None\n",
    "        # Check if game is over\n",
    "        elif board.is_insufficient_material() or not board.legal_moves or board.is_fifty_moves() or board.is_repetition(5):\n",
    "            # Game is very likely a draw\n",
    "            return 0, None\n",
    "\n",
    "        # Recursion abort case\n",
    "        if depth == 0:\n",
    "            return current_evaluation, None\n",
    "\n",
    "        # White to play (positive numbers are good)\n",
    "        if board.turn:\n",
    "            maxEvaluation = -self.LIMIT\n",
    "            for move in board.legal_moves:\n",
    "                next_move_evaluation = self.evaluate(board, move, current_evaluation)\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(board, depth - 1, next_move_evaluation)\n",
    "                board.pop()\n",
    "                if depth == self.DEPTH and evaluation >= maxEvaluation:\n",
    "                    best_move = move\n",
    "                maxEvaluation = max(maxEvaluation, evaluation)\n",
    "            return maxEvaluation, best_move\n",
    "\n",
    "        # Black to play (negative numbers are good)\n",
    "        else:\n",
    "            minEvaluation = self.LIMIT\n",
    "            for move in board.legal_moves:\n",
    "                next_move_evaluation = self.evaluate(board, move, current_evaluation)\n",
    "                board.push(move)\n",
    "                evaluation, _ = self.minimax(board, depth - 1, next_move_evaluation)\n",
    "                board.pop()\n",
    "                if depth == self.DEPTH and evaluation <= minEvaluation:\n",
    "                    best_move = move\n",
    "                minEvaluation = min(minEvaluation, evaluation)\n",
    "            return minEvaluation, best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berechnung des besten Zuges\n",
    "\n",
    "Die Funktion `get_next_middle_game_move` berechnet auf einem gegebenen Board den besten nächsten Zug. Dabei wird jeder mögliche Zug mithilfe der `minimax`-Funktion in der gewünschten Tiefe evaluiert und der Zug mit der besten Bewertung zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise02AI(Exercise02AI): # type: ignore\n",
    "    def get_next_middle_game_move(self, board: chess.Board) -> chess.Move | None:\n",
    "        \"\"\"Gets the best next move\"\"\"\n",
    "        if self.last_evaluation is None:  # type: ignore\n",
    "            current_evaluation = self.full_evaluate(board)\n",
    "        else:\n",
    "            last_move = board.pop()\n",
    "            # Get current evaluation (after opponent move)\n",
    "            current_evaluation = self.evaluate(board, last_move, self.last_evaluation)  # type: ignore\n",
    "            board.push(last_move)\n",
    "\n",
    "        # Call minimax and get best move\n",
    "        _, best_move = self.minimax(board, self.DEPTH, current_evaluation)\n",
    "        # Update last evaluation (after player move)\n",
    "        assert best_move, f\"\"\"\n",
    "        Best move is None with fen '{board.fen()}' at player {type(self).__name__}! \n",
    "        depth: {self.DEPTH}, last_eval: {self.last_evaluation}, current_evaluation: {current_evaluation},\n",
    "        is_king_engame: {getattr(self, 'is_king_endgame', \"N/A\")}, move_stack: {board.move_stack}\n",
    "        \"\"\"\n",
    "        self.last_evaluation = self.evaluate(board, best_move, current_evaluation)\n",
    "        return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Bereich\n",
    "\n",
    "Die folgenden Zellen enthalten Code zum Testen der oben implementierten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.Board(\"5rk1/1b3p2/8/3p4/3p2P1/2Q4B/5P1K/R3R3 b - - 0 36\")\n",
    "player = Exercise02AI(\"Testplayer\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_eval = player.evaluate(board)\n",
    "last_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board.push(chess.Move.from_uci(\"d4c3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(player.evaluate(board, last_eval))\n",
    "print(player.evaluate(board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def time_full_evals(num):\n",
    "    board = chess.Board()\n",
    "    player = Exercise02AI(\"Testplayer\", 3)\n",
    "    last_eval = player.evaluate(board)\n",
    "    start = time()\n",
    "    for _ in range(num):\n",
    "        move = list(board.legal_moves)[0]\n",
    "        board.push(move)\n",
    "        last_eval = player.evaluate(board)\n",
    "    end = time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_inc_evals(num):\n",
    "    board = chess.Board()\n",
    "    player = Exercise02AI(\"Testplayer\", 3)\n",
    "    last_eval = player.evaluate(board)\n",
    "    start = time()\n",
    "    for _ in range(num):\n",
    "        move = list(board.legal_moves)[0]\n",
    "        board.push(move)\n",
    "        last_eval = player.evaluate(board, last_eval)\n",
    "    end = time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_full_evals(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_inc_evals(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging function\n",
    "from IPython.display import display\n",
    "def display_path(board_orig, move, depth):\n",
    "    \"\"\"Displays the move path to the best evaluation.\"\"\"\n",
    "    board = deepcopy(board_orig)\n",
    "    display(board)\n",
    "    board.push(move)\n",
    "    display(board)\n",
    "    for i in range(depth, 0, -1):\n",
    "        move = Exercise02AI.path_history[str(board) + str(i)]\n",
    "        board.push(move)\n",
    "        display(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluate\n",
    "board = chess.Board(\"4k3/8/2n5/7K/5q2/2N5/8/2B5 b - - 0 1\")\n",
    "board.set_fen(\"4k3/8/2n5/7K/5q2/2N5/8/2B5 b - - 0 1\")\n",
    "board.push(list(board.legal_moves)[0])\n",
    "player = Exercise02AI(\"Testplayer\", 3)\n",
    "\n",
    "player.evaluate(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluate\n",
    "board = chess.Board(\"4k3/5p2/8/6P1/8/8/8/4K3 b - - 0 1\")\n",
    "board.push(chess.Move.from_uci('f7f5')) # two square pawn move\n",
    "board.push(chess.Move.from_uci('g5f6')) # en passant capture\n",
    "player = Exercise02AI(\"Testplayer\", 3)\n",
    "player.evaluate(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Test get_next_middle_game_move\n",
    "DEPTH = 3\n",
    "board = chess.Board()\n",
    "board.set_fen(\"4k3/8/2n5/7K/5q2/2N5/8/2B5 b - - 0 1\")\n",
    "player = Exercise02AI(\"Testplayer\", DEPTH)\n",
    "#print(player.minimax(board, DEPTH))\n",
    "move = player.get_next_middle_game_move(board)\n",
    "print(move)\n",
    "#display_path(board, move, DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
